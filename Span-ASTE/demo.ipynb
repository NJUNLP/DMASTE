{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "izKXA4b6-oIv",
        "outputId": "42cc17d7-ef24-42d4-d0b4-05f1db5c10af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Span-ASTE'...\n",
            "remote: Enumerating objects: 104, done.\u001b[K\n",
            "remote: Counting objects: 100% (104/104), done.\u001b[K\n",
            "remote: Compressing objects: 100% (78/78), done.\u001b[K\n",
            "remote: Total 104 (delta 36), reused 77 (delta 21), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (104/104), 519.43 KiB | 5.19 MiB/s, done.\n",
            "Resolving deltas: 100% (36/36), done.\n",
            "Note: checking out '7cbf035'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at 7cbf035 Add SpanModel with scikit-learn-style methods for easy usage (fit, predict, score)\n",
            "Collecting Cython==0.29.21\n",
            "  Downloading Cython-0.29.21-cp37-cp37m-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 5.1 MB/s \n",
            "\u001b[?25hCollecting PYEVALB==0.1.3\n",
            "  Downloading PYEVALB-0.1.3-py3-none-any.whl (13 kB)\n",
            "Collecting allennlp-models==1.2.2\n",
            "  Downloading allennlp_models-1.2.2-py3-none-any.whl (353 kB)\n",
            "\u001b[K     |████████████████████████████████| 353 kB 38.9 MB/s \n",
            "\u001b[?25hCollecting allennlp==1.2.2\n",
            "  Downloading allennlp-1.2.2-py3-none-any.whl (505 kB)\n",
            "\u001b[K     |████████████████████████████████| 505 kB 49.8 MB/s \n",
            "\u001b[?25hCollecting botocore==1.19.46\n",
            "  Downloading botocore-1.19.46-py2.py3-none-any.whl (7.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.2 MB 24.1 MB/s \n",
            "\u001b[?25hCollecting fire==0.3.1\n",
            "  Downloading fire-0.3.1.tar.gz (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 10.0 MB/s \n",
            "\u001b[?25hCollecting nltk==3.6.6\n",
            "  Downloading nltk-3.6.6-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 37.5 MB/s \n",
            "\u001b[?25hCollecting numpy==1.21.5\n",
            "  Downloading numpy-1.21.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 31.9 MB/s \n",
            "\u001b[?25hCollecting pandas==1.1.5\n",
            "  Downloading pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.5 MB 22.2 MB/s \n",
            "\u001b[?25hCollecting pydantic==1.6.2\n",
            "  Downloading pydantic-1.6.2-cp37-cp37m-manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.6 MB 19.5 MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.22.2.post1\n",
            "  Downloading scikit_learn-0.22.2.post1-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 31.1 MB/s \n",
            "\u001b[?25hCollecting torch==1.7.0\n",
            "  Downloading torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (776.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.7 MB 4.7 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.8.1\n",
            "  Downloading torchvision-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (12.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.7 MB 33.5 MB/s \n",
            "\u001b[?25hCollecting transformers==3.4.0\n",
            "  Downloading transformers-3.4.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 35.0 MB/s \n",
            "\u001b[?25hCollecting pytablewriter>=0.10.2\n",
            "  Downloading pytablewriter-0.64.2-py3-none-any.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 50.2 MB/s \n",
            "\u001b[?25hCollecting word2number>=1.1\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "Collecting conllu==4.2.1\n",
            "  Downloading conllu-4.2.1-py2.py3-none-any.whl (14 kB)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.3 MB/s \n",
            "\u001b[?25hCollecting py-rouge==1.1\n",
            "  Downloading py_rouge-1.1-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.7/dist-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (4.64.0)\n",
            "Collecting tensorboardX>=1.2\n",
            "  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 45.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.18 in /usr/local/lib/python3.7/dist-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (2.23.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (1.4.1)\n",
            "Collecting filelock<3.1,>=3.0\n",
            "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
            "Collecting boto3<2.0,>=1.14\n",
            "  Downloading boto3-1.22.2-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 38.7 MB/s \n",
            "\u001b[?25hCollecting overrides==3.1.0\n",
            "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (3.6.4)\n",
            "Requirement already satisfied: spacy<2.4,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (2.2.4)\n",
            "Collecting jsonpickle\n",
            "  Downloading jsonpickle-2.1.0-py2.py3-none-any.whl (38 kB)\n",
            "Collecting jsonnet>=0.10.0\n",
            "  Downloading jsonnet-0.18.0.tar.gz (592 kB)\n",
            "\u001b[K     |████████████████████████████████| 592 kB 49.1 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 47.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore==1.19.46->-r requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fire==0.3.1->-r requirements.txt (line 6)) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire==0.3.1->-r requirements.txt (line 6)) (1.1.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.6->-r requirements.txt (line 7)) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.6->-r requirements.txt (line 7)) (7.1.2)\n",
            "Collecting regex>=2021.8.3\n",
            "  Downloading regex-2022.4.24-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
            "\u001b[K     |████████████████████████████████| 749 kB 49.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.5->-r requirements.txt (line 9)) (2022.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->-r requirements.txt (line 12)) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->-r requirements.txt (line 12)) (4.2.0)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.1->-r requirements.txt (line 13)) (7.1.2)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 39.8 MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.2\n",
            "  Downloading tokenizers-0.9.2-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 36.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 14)) (21.3)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 39.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 14)) (3.17.3)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.3 MB/s \n",
            "\u001b[?25hCollecting boto3<2.0,>=1.14\n",
            "  Downloading boto3-1.22.1-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 50.5 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.22.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 49.5 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.46-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 37.9 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.45-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 52.4 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.44-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 48.9 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.43-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 51.6 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.42-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 45.1 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.41-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 50.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.40-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 50.2 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.39-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 49.0 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.38-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 47.9 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.37-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 50.0 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.36-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 49.6 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.35-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 53.5 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.34-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 49.6 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.33-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 42.1 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.32-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 50.2 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.31-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 46.3 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.30-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 51.0 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.29-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 50.7 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.28-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 50.1 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.27-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 44.6 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.26-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 35.3 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.25-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 46.5 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.24-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 48.0 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.23-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 50.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.22-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 51.6 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.21-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 48.5 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.20-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 53.3 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.19-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 50.6 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.18-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 49.7 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.17-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 45.3 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.16-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 37.4 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.15-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 50.5 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.14-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 48.2 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.13-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 49.5 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.12-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 53.5 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.11-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 47.4 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.10-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 47.6 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.9-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 49.4 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.8-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 50.3 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.7-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 52.7 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.6-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 49.9 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.5-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 48.4 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.4-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 49.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.3-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 51.1 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.2-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 23.6 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.1-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 46.9 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.21.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 49.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.54-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 45.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.53-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 52.2 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.52-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 48.1 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.51-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.0 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.50-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 48.9 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.49-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 47.7 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.48-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.6 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.47-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 29.0 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.46-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.7 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.45-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 53.1 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.44-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 48.9 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.43-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 43.1 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.42-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 51.9 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.41-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 47.2 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.40-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 48.7 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.39-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 48.4 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.38-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 49.7 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.37-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.7 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.36-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 49.3 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.35-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 53.5 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.34-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 37.6 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.33-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.5 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.32-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 32.1 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.31-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 48.4 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.30-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 54.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.29-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 49.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.28-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 44.4 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.27-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 51.0 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.26-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.25-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 52.9 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.24-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 39.4 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.23-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 52.7 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.22-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 51.0 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.21-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 49.0 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.20-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.7 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.19-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 49.4 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.18-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.0 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.17-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 47.1 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.16-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 49.4 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.15-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 53.7 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.14-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 53.3 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.13-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.0 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.12-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 49.7 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.11-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 53.3 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.10-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 53.1 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.9-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 45.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.8-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 46.0 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.7-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.5 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.6-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 42.2 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.5-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 48.2 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.4-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.6 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.3-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.2-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 47.7 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.1-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 43.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.20.0-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 48.0 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.19.12-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 40.7 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.19.11-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 51.3 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.19.10-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 54.5 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.19.9-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 51.6 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.19.8-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 49.6 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.19.7-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 53.4 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.19.6-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 49.1 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.19.5-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 49.6 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.19.4-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 51.9 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.19.3-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 46.7 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.19.2-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 52.0 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.19.1-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 51.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.19.0-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.1 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.65-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 48.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.64-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 52.3 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.63-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 51.9 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.62-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 49.7 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.61-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 46.5 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.60-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 47.5 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.59-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.5 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.58-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.6 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.57-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.3 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.56-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 46.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.55-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 52.7 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.54-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 33.9 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.53-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 51.6 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.52-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 51.3 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.51-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.6 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.50-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 52.6 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.49-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.5 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.48-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 48.6 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.47-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 51.6 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.46-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 48.1 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.45-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 47.3 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.44-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 52.7 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.43-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 51.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.42-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 45.2 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.41-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 24.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.40-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 13.1 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.39-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 51.3 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.38-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.0 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.37-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 46.4 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.36-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 47.9 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.35-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 44.6 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.34-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 44.9 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.33-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 48.1 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.32-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 42.0 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.31-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 52.2 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.30-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.7 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.29-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 48.6 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.28-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 46.7 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.27-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 43.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.26-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 48.1 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.25-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 47.4 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.24-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 47.1 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.23-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 51.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.22-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.5 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.21-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 47.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.20-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 49.4 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.19-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 47.9 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.18-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 47.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.17-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 51.5 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.16-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 48.9 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.15-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 53.7 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.14-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 48.7 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.13-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 49.4 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.12-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.11-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 52.2 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.10-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 51.3 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.9-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 28.1 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.8-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 45.7 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.7-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 48.0 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.6-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.4 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.5-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.1 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.4-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 48.0 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.3-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 48.7 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.2-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 47.0 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.1-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 34.2 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.18.0-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 46.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.112-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 46.8 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.5.0,>=0.4.0\n",
            "  Downloading s3transfer-0.4.2-py2.py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.5 MB/s \n",
            "\u001b[?25hCollecting boto3<2.0,>=1.14\n",
            "  Downloading boto3-1.17.111-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 48.1 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.110-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 51.9 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.109-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 43.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.108-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 51.2 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.107-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 40.5 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.106-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 51.0 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.105-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 52.5 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.104-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 51.6 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.103-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 48.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.102-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 44.9 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.101-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 16.6 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.100-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 51.4 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.99-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 45.9 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.98-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 49.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.97-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.0 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.96-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 49.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.95-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 38.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.94-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 52.1 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.93-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 46.7 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.92-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.91-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.4 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.90-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 46.5 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.89-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 51.0 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.88-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 49.9 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.87-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 32.2 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.86-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 36.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.85-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 51.1 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.84-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 49.1 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.83-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 47.7 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.82-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 52.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.81-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 51.2 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.80-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 49.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.79-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 45.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.78-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 53.5 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.77-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 48.6 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.76-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 46.3 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.75-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 46.9 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.74-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 51.7 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.73-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 53.9 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.72-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.6 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.71-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 48.4 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.70-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.3 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.69-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 47.6 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.68-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 45.4 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.67-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 51.4 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.66-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 49.7 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.65-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 47.3 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.64-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 38.3 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.63-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 43.6 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.62-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 51.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.61-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.2 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.60-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 36.1 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.59-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 52.2 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.58-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 46.4 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.57-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 44.2 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.56-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 51.5 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.55-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.4 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.54-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 53.1 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.53-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.9 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n",
            "  Downloading s3transfer-0.3.7-py2.py3-none-any.whl (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting boto3<2.0,>=1.14\n",
            "  Downloading boto3-1.17.52-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.5 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.51-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 43.7 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.50-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 52.9 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.49-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.2 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.48-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.0 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.47-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 49.0 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.46-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 46.1 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.45-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 49.6 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.44-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 52.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.43-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 52.0 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.42-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.4 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.41-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 49.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.40-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 42.5 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.39-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 51.1 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.38-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 40.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.37-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 46.9 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.36-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 51.3 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.35-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 54.1 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.34-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 51.5 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.33-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.5 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.32-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 51.7 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.31-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 51.4 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.30-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.3 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.29-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 47.0 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.28-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 48.2 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.27-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 46.4 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.26-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 49.2 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.25-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 48.2 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.24-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 49.6 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.23-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 51.2 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.22-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 51.4 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.21-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 50.0 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.20-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 26.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.19-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 38.3 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.18-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 40.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.17-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 43.5 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.16-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 49.4 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.15-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 51.1 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.14-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 51.4 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.13-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 47.6 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.12-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 49.7 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.11-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 51.4 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.10-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 49.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.9-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 47.4 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.8-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 46.9 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.7-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 45.9 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.6-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 49.0 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.5-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 51.0 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.4-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 50.2 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.3-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 51.5 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.2-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 47.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.1-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 50.7 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.17.0-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 51.2 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.16.63-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 38.9 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.16.62-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 49.9 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.16.61-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 51.1 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.16.60-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 44.4 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.16.59-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 51.0 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.16.58-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 53.1 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.16.57-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 46.4 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.16.56-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 49.5 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.16.55-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 44.8 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.16.54-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 49.2 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.16.53-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 50.7 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.16.52-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 49.7 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.16.51-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 49.9 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.16.50-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 37.5 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.16.49-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 48.5 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.16.48-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 53.6 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.16.47-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 50.9 MB/s \n",
            "\u001b[?25h  Downloading boto3-1.16.46-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 50.9 MB/s \n",
            "\u001b[?25hCollecting typepy[datetime]<2,>=1.2.0\n",
            "  Downloading typepy-1.3.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.7/dist-packages (from pytablewriter>=0.10.2->PYEVALB==0.1.3->-r requirements.txt (line 2)) (57.4.0)\n",
            "Collecting DataProperty<2,>=0.55.0\n",
            "  Downloading DataProperty-0.55.0-py3-none-any.whl (26 kB)\n",
            "Collecting tabledata<2,>=1.3.0\n",
            "  Downloading tabledata-1.3.0-py3-none-any.whl (11 kB)\n",
            "Collecting pathvalidate<3,>=2.3.0\n",
            "  Downloading pathvalidate-2.5.0-py3-none-any.whl (19 kB)\n",
            "Collecting tcolorpy<1,>=0.0.5\n",
            "  Downloading tcolorpy-0.1.2-py3-none-any.whl (7.9 kB)\n",
            "Collecting mbstrdecoder<2,>=1.0.0\n",
            "  Downloading mbstrdecoder-1.1.0-py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: chardet<5,>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter>=0.10.2->PYEVALB==0.1.3->-r requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==1.2.2->-r requirements.txt (line 4)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==1.2.2->-r requirements.txt (line 4)) (2021.10.8)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 50.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (2.0.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (1.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (0.9.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (3.0.6)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (3.8.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->allennlp-models==1.2.2->-r requirements.txt (line 3)) (0.2.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->allennlp==1.2.2->-r requirements.txt (line 4)) (1.5.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.4.0->-r requirements.txt (line 14)) (3.0.8)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==1.2.2->-r requirements.txt (line 4)) (0.7.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==1.2.2->-r requirements.txt (line 4)) (1.4.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==1.2.2->-r requirements.txt (line 4)) (8.12.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==1.2.2->-r requirements.txt (line 4)) (21.4.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==1.2.2->-r requirements.txt (line 4)) (1.11.0)\n",
            "Building wheels for collected packages: fire, overrides, jsonnet, word2number\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.3.1-py2.py3-none-any.whl size=111023 sha256=d47810845b59a5ae3c25917107253e1a2bbd302b4e119497b8205e38218a649f\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/38/e1/8b62337a8ecf5728bdc1017e828f253f7a9cf25db999861bec\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10187 sha256=7fbb7d53121ab1531cb2d7faaf5761b67821d59b8ecd5f2e92d47cb314fcd140\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/0d/38/01a9bc6e20dcfaf0a6a7b552d03137558ba1c38aea47644682\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.18.0-cp37-cp37m-linux_x86_64.whl size=3994704 sha256=f02ffdc677d48a08142bfc3d71b0830444badc120951d1426aae3fe3a8f7c541\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/63/f9/a653f9c21575e6ff271ee6a49939aa002005174cea6c35919d\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5582 sha256=90730ad0f27eabad028c54c80863654c042ca6a31a085cee7a8797ef6e4dacd0\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/c3/77/a5f48aeb0d3efb7cd5ad61cbd3da30bbf9ffc9662b07c9f879\n",
            "Successfully built fire overrides jsonnet word2number\n",
            "Installing collected packages: mbstrdecoder, urllib3, typepy, numpy, jmespath, regex, botocore, tokenizers, sentencepiece, sacremoses, s3transfer, filelock, DataProperty, dataclasses, transformers, torch, tensorboardX, tcolorpy, tabledata, scikit-learn, pathvalidate, overrides, nltk, jsonpickle, jsonnet, boto3, word2number, pytablewriter, py-rouge, ftfy, conllu, allennlp, torchvision, PYEVALB, pydantic, pandas, fire, Cython, allennlp-models\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.6.0\n",
            "    Uninstalling filelock-3.6.0:\n",
            "      Successfully uninstalled filelock-3.6.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.12.0+cu113\n",
            "    Uninstalling torchvision-0.12.0+cu113:\n",
            "      Successfully uninstalled torchvision-0.12.0+cu113\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: Cython\n",
            "    Found existing installation: Cython 0.29.28\n",
            "    Uninstalling Cython-0.29.28:\n",
            "      Successfully uninstalled Cython-0.29.28\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.22.2.post1 which is incompatible.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.7.0 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.7.0 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.2.post1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Cython-0.29.21 DataProperty-0.55.0 PYEVALB-0.1.3 allennlp-1.2.2 allennlp-models-1.2.2 boto3-1.16.46 botocore-1.19.46 conllu-4.2.1 dataclasses-0.6 filelock-3.0.12 fire-0.3.1 ftfy-6.1.1 jmespath-0.10.0 jsonnet-0.18.0 jsonpickle-2.1.0 mbstrdecoder-1.1.0 nltk-3.6.6 numpy-1.21.5 overrides-3.1.0 pandas-1.1.5 pathvalidate-2.5.0 py-rouge-1.1 pydantic-1.6.2 pytablewriter-0.64.2 regex-2022.4.24 s3transfer-0.3.7 sacremoses-0.0.49 scikit-learn-0.22.2.post1 sentencepiece-0.1.96 tabledata-1.3.0 tcolorpy-0.1.2 tensorboardX-2.5 tokenizers-0.9.2 torch-1.7.0 torchvision-0.8.1 transformers-3.4.0 typepy-1.3.0 urllib3-1.25.11 word2number-1.1\n",
            "Found existing installation: dataclasses 0.6\n",
            "Uninstalling dataclasses-0.6:\n",
            "  Successfully uninstalled dataclasses-0.6\n",
            "Archive:  data.zip\n",
            "   creating: aste/data/\n",
            "   creating: aste/data/triplet_data/\n",
            "   creating: aste/data/triplet_data/14lap/\n",
            "  inflating: aste/data/triplet_data/14lap/dev.txt  \n",
            "  inflating: aste/data/triplet_data/14lap/test.txt  \n",
            "  inflating: aste/data/triplet_data/14lap/train.txt  \n",
            "   creating: aste/data/triplet_data/14res/\n",
            "  inflating: aste/data/triplet_data/14res/dev.txt  \n",
            "  inflating: aste/data/triplet_data/14res/test.txt  \n",
            "  inflating: aste/data/triplet_data/14res/train.txt  \n",
            "   creating: aste/data/triplet_data/15res/\n",
            "  inflating: aste/data/triplet_data/15res/dev.txt  \n",
            "  inflating: aste/data/triplet_data/15res/test.txt  \n",
            "  inflating: aste/data/triplet_data/15res/train.txt  \n",
            "   creating: aste/data/triplet_data/16res/\n",
            "  inflating: aste/data/triplet_data/16res/dev.txt  \n",
            "  inflating: aste/data/triplet_data/16res/test.txt  \n",
            "  inflating: aste/data/triplet_data/16res/train.txt  \n",
            "--2022-04-28 06:06:47--  https://github.com/chiayewken/Span-ASTE/releases/download/v1.0.0/pretrained_14lap.tar\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/371216048/7cc1d21a-b509-4c64-a3ea-ed04f6d5639c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220428%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220428T060647Z&X-Amz-Expires=300&X-Amz-Signature=66a165a6afe6911c411812f23b52f96bd92d69567b6ef759168879e0cfe4a7e8&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=371216048&response-content-disposition=attachment%3B%20filename%3Dpretrained_14lap.tar&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-04-28 06:06:47--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/371216048/7cc1d21a-b509-4c64-a3ea-ed04f6d5639c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220428%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220428T060647Z&X-Amz-Expires=300&X-Amz-Signature=66a165a6afe6911c411812f23b52f96bd92d69567b6ef759168879e0cfe4a7e8&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=371216048&response-content-disposition=attachment%3B%20filename%3Dpretrained_14lap.tar&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 408453120 (390M) [application/octet-stream]\n",
            "Saving to: ‘pretrained_14lap.tar’\n",
            "\n",
            "pretrained_14lap.ta 100%[===================>] 389.53M  61.0MB/s    in 6.1s    \n",
            "\n",
            "2022-04-28 06:06:53 (64.1 MB/s) - ‘pretrained_14lap.tar’ saved [408453120/408453120]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/chiayewken/Span-ASTE.git\n",
        "!cd Span-ASTE && git checkout 7cbf035\n",
        "!cp -a Span-ASTE/* .\n",
        "!bash setup.sh\n",
        "!wget https://github.com/chiayewken/Span-ASTE/releases/download/v1.0.0/pretrained_14lap.tar\n",
        "!tar -xf pretrained_14lap.tar"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data Exploration\n",
        "data_name = \"14lap\" #@param [\"14lap\", \"14res\", \"15res\", \"16res\"]\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"aste\")\n",
        "from data_utils import Data\n",
        "\n",
        "path = f\"aste/data/triplet_data/{data_name}/train.txt\"\n",
        "data = Data.load_from_full_path(path)\n",
        "\n",
        "for s in data.sentences[:3]:\n",
        "    print(\"tokens:\", s.tokens)\n",
        "    for t in s.triples:\n",
        "        print(\"target:\", (t.t_start, t.t_end))\n",
        "        print(\"opinion:\", (t.o_start, t.o_end))\n",
        "        print(\"label:\", t.label)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pTnCgDxcSQ5",
        "outputId": "bd03e983-0bc1-4cba-80a8-704fba16b9d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokens: ['I', 'charge', 'it', 'at', 'night', 'and', 'skip', 'taking', 'the', 'cord', 'with', 'me', 'because', 'of', 'the', 'good', 'battery', 'life', '.']\n",
            "target: (16, 17)\n",
            "opinion: (15, 15)\n",
            "label: LabelEnum.positive\n",
            "\n",
            "tokens: ['it', 'is', 'of', 'high', 'quality', ',', 'has', 'a', 'killer', 'GUI', ',', 'is', 'extremely', 'stable', ',', 'is', 'highly', 'expandable', ',', 'is', 'bundled', 'with', 'lots', 'of', 'very', 'good', 'applications', ',', 'is', 'easy', 'to', 'use', ',', 'and', 'is', 'absolutely', 'gorgeous', '.']\n",
            "target: (4, 4)\n",
            "opinion: (3, 3)\n",
            "label: LabelEnum.positive\n",
            "target: (9, 9)\n",
            "opinion: (8, 8)\n",
            "label: LabelEnum.positive\n",
            "target: (26, 26)\n",
            "opinion: (25, 25)\n",
            "label: LabelEnum.positive\n",
            "target: (31, 31)\n",
            "opinion: (29, 29)\n",
            "label: LabelEnum.positive\n",
            "\n",
            "tokens: ['Easy', 'to', 'start', 'up', 'and', 'does', 'not', 'overheat', 'as', 'much', 'as', 'other', 'laptops', '.']\n",
            "target: (2, 3)\n",
            "opinion: (0, 0)\n",
            "label: LabelEnum.positive\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3i4rnIhapWe",
        "outputId": "f1bdb354-9bb6-43f3-cff3-3f54ad9c699b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'command': 'cd /content && allennlp predict pretrained_14lap/weights/model.tar.gz /content/pretrained_14lap/temp_data/pred_in.json --predictor span_model --include-package span_model --use-dataset-reader  --output-file pretrained_14lap/temp_data/pred_out.json --cuda-device 0 --silent '}\n",
            "################################################################################\n",
            "################################################################################\n",
            "{'locals': ('use_ner_embeds', False)}\n",
            "{'locals': ('span_extractor_type', 'endpoint')}\n",
            "{'locals': ('use_double_mix_embedder', False)}\n",
            "{'locals': ('relation_head_type', 'proper')}\n",
            "{'locals': ('use_span_width_embeds', True)}\n",
            "{'ner_loss_fn': CrossEntropyLoss()}\n",
            "{'unused_keys': dict_keys(['focal_loss_gamma', 'use_bi_affine_pruner', 'use_classify_mask_pruner', 'use_focal_loss', 'use_ner_scores_for_prune', 'use_ope_down_project', 'use_pair_feature_multiply', 'use_pairwise_down_project', 'use_span_loss_for_pruners', 'use_span_pair_aux_task', 'use_span_pair_aux_task_after_prune'])}\n",
            "{'locals': {'self': ProperRelationExtractor(), 'make_feedforward': <function SpanModel.__init__.<locals>.make_feedforward at 0x7fbde102e7a0>, 'span_emb_dim': 1556, 'feature_size': 20, 'spans_per_word': 0.5, 'positive_label_weight': 1.0, 'regularizer': None, 'use_distance_embeds': True, 'use_pair_feature_maxpool': False, 'use_pair_feature_cls': False, 'use_bi_affine_classifier': False, 'neg_class_weight': -1, 'span_length_loss_weight_gamma': 0, 'use_bag_pair_scorer': False, 'use_bi_affine_v2': False, 'use_pruning': True, 'use_single_pool': False, 'kwargs': {'focal_loss_gamma': 2, 'use_bi_affine_pruner': False, 'use_classify_mask_pruner': False, 'use_focal_loss': False, 'use_ner_scores_for_prune': False, 'use_ope_down_project': False, 'use_pair_feature_multiply': False, 'use_pairwise_down_project': False, 'use_span_loss_for_pruners': False, 'use_span_pair_aux_task': False, 'use_span_pair_aux_task_after_prune': False}, 'vocab': Vocabulary with namespaces:  None__tag_labels, Size: 9 || None__ner_labels, Size: 3 || None__relation_labels, Size: 3 || Non Padded Namespaces: {'*tags', '*labels'}, '__class__': <class 'span_model.models.relation_proper.ProperRelationExtractor'>}}\n",
            "{'token_emb_dim': 768, 'span_emb_dim': 1556, 'relation_scorer_dim': 3240}\n",
            "{'relation_loss_fn': CrossEntropyLoss()}\n",
            "{'file_path': '/content/pretrained_14lap/temp_data/pred_in.json', 'stats': Stats(entity_total=1, entity_drop=0, relation_total=1, relation_drop=0, graph_total=0, graph_edges=0, grid_total=121, grid_paired=1)}\n",
            "\n",
            "{'target': 'Windows 8', 'opinion': 'not enjoy', 'sentiment': <LabelEnum.negative: 'NEG'>}\n",
            "\n",
            "{'target': 'touchscreen functions', 'opinion': 'not enjoy', 'sentiment': <LabelEnum.negative: 'NEG'>}\n"
          ]
        }
      ],
      "source": [
        "# Use pretrained SpanModel weights for prediction\n",
        "import sys\n",
        "sys.path.append(\"aste\")\n",
        "from pathlib import Path\n",
        "from data_utils import Data, Sentence, SplitEnum\n",
        "from wrapper import SpanModel\n",
        "\n",
        "def predict_sentence(text: str, model: SpanModel) -> Sentence:\n",
        "    path_in = \"temp_in.txt\"\n",
        "    path_out = \"temp_out.txt\"\n",
        "    sent = Sentence(tokens=text.split(), triples=[], pos=[], is_labeled=False, weight=1, id=0)\n",
        "    data = Data(root=Path(), data_split=SplitEnum.test, sentences=[sent])\n",
        "    data.save_to_path(path_in)\n",
        "    model.predict(path_in, path_out)\n",
        "    data = Data.load_from_full_path(path_out)\n",
        "    return data.sentences[0]\n",
        "\n",
        "text = \"Did not enjoy the new Windows 8 and touchscreen functions .\"\n",
        "model = SpanModel(save_dir=\"pretrained_14lap\", random_seed=0)\n",
        "sent = predict_sentence(text, model)\n",
        "\n",
        "for t in sent.triples:\n",
        "    target = \" \".join(sent.tokens[t.t_start:t.t_end+1])\n",
        "    opinion = \" \".join(sent.tokens[t.o_start:t.o_end+1])\n",
        "    print()\n",
        "    print(dict(target=target, opinion=opinion, sentiment=t.label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "srSNwqUz-39x",
        "outputId": "d1c5da8b-a03b-486e-da6a-66632c2c6ab2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'weights_dir': PosixPath('outputs/14lap/seed_0/weights')}\n",
            "{'random_seed': 0}\n",
            "{'pytorch_seed': 0}\n",
            "{'numpy_seed': 0}\n",
            "{'train_data_path': PosixPath('/content/outputs/14lap/seed_0/temp_data/train.json')}\n",
            "{'validation_data_path': PosixPath('/content/outputs/14lap/seed_0/temp_data/validation.json')}\n",
            "{'test_data_path': PosixPath('/content/outputs/14lap/seed_0/temp_data/test.json')}\n",
            "{'path_config': PosixPath('outputs/14lap/seed_0/config.jsonnet')}\n",
            "{'command': 'cd /content && allennlp train outputs/14lap/seed_0/config.jsonnet --serialization-dir outputs/14lap/seed_0/weights --include-package span_model'}\n",
            "2022-04-28 06:11:40,547 - INFO - allennlp.common.params - random_seed = 0\n",
            "2022-04-28 06:11:40,547 - INFO - allennlp.common.params - numpy_seed = 0\n",
            "2022-04-28 06:11:40,548 - INFO - allennlp.common.params - pytorch_seed = 0\n",
            "2022-04-28 06:11:40,552 - INFO - allennlp.common.checks - Pytorch version: 1.7.0\n",
            "2022-04-28 06:11:40,552 - INFO - allennlp.common.params - type = default\n",
            "2022-04-28 06:11:40,554 - INFO - allennlp.common.params - dataset_reader.type = span_model\n",
            "2022-04-28 06:11:40,554 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
            "2022-04-28 06:11:40,555 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
            "2022-04-28 06:11:40,555 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
            "2022-04-28 06:11:40,555 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
            "2022-04-28 06:11:40,556 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
            "2022-04-28 06:11:40,556 - INFO - allennlp.common.params - dataset_reader.max_span_width = 8\n",
            "2022-04-28 06:11:40,557 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.type = pretrained_transformer_mismatched\n",
            "2022-04-28 06:11:40,557 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.token_min_padding_length = 0\n",
            "2022-04-28 06:11:40,558 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.model_name = bert-base-uncased\n",
            "2022-04-28 06:11:40,558 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.namespace = tags\n",
            "2022-04-28 06:11:40,559 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.max_length = 512\n",
            "2022-04-28 06:11:40,559 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.tokenizer_kwargs = None\n",
            "################################################################################\n",
            "2022-04-28 06:11:41,488 - INFO - allennlp.common.params - train_data_path = /content/outputs/14lap/seed_0/temp_data/train.json\n",
            "2022-04-28 06:11:41,489 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x7f62aabf5510>\n",
            "2022-04-28 06:11:41,489 - INFO - allennlp.common.params - datasets_for_vocab_creation = None\n",
            "2022-04-28 06:11:41,489 - INFO - allennlp.common.params - validation_dataset_reader = None\n",
            "2022-04-28 06:11:41,489 - INFO - allennlp.common.params - validation_data_path = /content/outputs/14lap/seed_0/temp_data/validation.json\n",
            "2022-04-28 06:11:41,490 - INFO - allennlp.common.params - validation_data_loader = None\n",
            "2022-04-28 06:11:41,490 - INFO - allennlp.common.params - test_data_path = /content/outputs/14lap/seed_0/temp_data/test.json\n",
            "2022-04-28 06:11:41,490 - INFO - allennlp.common.params - evaluate_on_test = False\n",
            "2022-04-28 06:11:41,490 - INFO - allennlp.common.params - batch_weight_key =\n",
            "2022-04-28 06:11:41,490 - INFO - allennlp.training.util - Reading training data from /content/outputs/14lap/seed_0/temp_data/train.json\n",
            "{'file_path': '/content/outputs/14lap/seed_0/temp_data/train.json', 'stats': Stats(entity_total=2548, entity_drop=0, relation_total=1460, relation_drop=0, graph_total=0, graph_edges=0, grid_total=438060, grid_paired=2274)}\n",
            "2022-04-28 06:11:42,866 - INFO - allennlp.training.util - Reading validation data from /content/outputs/14lap/seed_0/temp_data/validation.json\n",
            "{'file_path': '/content/outputs/14lap/seed_0/temp_data/validation.json', 'stats': Stats(entity_total=600, entity_drop=0, relation_total=345, relation_drop=0, graph_total=0, graph_edges=0, grid_total=107881, grid_paired=553)}\n",
            "2022-04-28 06:11:43,060 - INFO - allennlp.training.util - Reading test data from /content/outputs/14lap/seed_0/temp_data/test.json\n",
            "{'file_path': '/content/outputs/14lap/seed_0/temp_data/test.json', 'stats': Stats(entity_total=600, entity_drop=0, relation_total=345, relation_drop=0, graph_total=0, graph_edges=0, grid_total=107881, grid_paired=553)}\n",
            "2022-04-28 06:11:43,539 - INFO - allennlp.common.params - type = from_instances\n",
            "2022-04-28 06:11:43,540 - INFO - allennlp.common.params - min_count = None\n",
            "2022-04-28 06:11:43,540 - INFO - allennlp.common.params - max_vocab_size = None\n",
            "2022-04-28 06:11:43,540 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')\n",
            "2022-04-28 06:11:43,541 - INFO - allennlp.common.params - pretrained_files = None\n",
            "2022-04-28 06:11:43,541 - INFO - allennlp.common.params - only_include_pretrained_words = False\n",
            "2022-04-28 06:11:43,541 - INFO - allennlp.common.params - tokens_to_add = None\n",
            "2022-04-28 06:11:43,541 - INFO - allennlp.common.params - min_pretrained_embeddings = None\n",
            "2022-04-28 06:11:43,542 - INFO - allennlp.common.params - padding_token = @@PADDING@@\n",
            "2022-04-28 06:11:43,542 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@\n",
            "2022-04-28 06:11:43,542 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.\n",
            "2022-04-28 06:11:43,639 - INFO - allennlp.common.params - model.type = span_model\n",
            "2022-04-28 06:11:43,640 - INFO - allennlp.common.params - model.embedder.type = basic\n",
            "2022-04-28 06:11:43,641 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.type = pretrained_transformer_mismatched\n",
            "2022-04-28 06:11:43,642 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.model_name = bert-base-uncased\n",
            "2022-04-28 06:11:43,642 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.max_length = 512\n",
            "2022-04-28 06:11:43,642 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.train_parameters = True\n",
            "2022-04-28 06:11:43,642 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.last_layer_only = True\n",
            "2022-04-28 06:11:43,643 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.gradient_checkpointing = None\n",
            "2022-04-28 06:11:43,643 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.tokenizer_kwargs = None\n",
            "2022-04-28 06:11:43,643 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.transformer_kwargs = None\n",
            "2022-04-28 06:11:47,363 - INFO - allennlp.common.params - model.modules.ner.focal_loss_gamma = 2\n",
            "2022-04-28 06:11:47,363 - INFO - allennlp.common.params - model.modules.ner.neg_class_weight = -1\n",
            "2022-04-28 06:11:47,363 - INFO - allennlp.common.params - model.modules.ner.use_bi_affine = False\n",
            "2022-04-28 06:11:47,363 - INFO - allennlp.common.params - model.modules.ner.use_double_scorer = False\n",
            "2022-04-28 06:11:47,363 - INFO - allennlp.common.params - model.modules.ner.use_focal_loss = False\n",
            "2022-04-28 06:11:47,363 - INFO - allennlp.common.params - model.modules.ner.use_gold_for_train_prune_scores = False\n",
            "2022-04-28 06:11:47,364 - INFO - allennlp.common.params - model.modules.ner.use_single_pool = False\n",
            "2022-04-28 06:11:47,364 - INFO - allennlp.common.params - model.modules.relation.focal_loss_gamma = 2\n",
            "2022-04-28 06:11:47,364 - INFO - allennlp.common.params - model.modules.relation.neg_class_weight = -1\n",
            "2022-04-28 06:11:47,364 - INFO - allennlp.common.params - model.modules.relation.span_length_loss_weight_gamma = 0\n",
            "2022-04-28 06:11:47,364 - INFO - allennlp.common.params - model.modules.relation.spans_per_word = 0.5\n",
            "2022-04-28 06:11:47,365 - INFO - allennlp.common.params - model.modules.relation.use_bag_pair_scorer = False\n",
            "2022-04-28 06:11:47,365 - INFO - allennlp.common.params - model.modules.relation.use_bi_affine_classifier = False\n",
            "2022-04-28 06:11:47,365 - INFO - allennlp.common.params - model.modules.relation.use_bi_affine_pruner = False\n",
            "2022-04-28 06:11:47,365 - INFO - allennlp.common.params - model.modules.relation.use_bi_affine_v2 = False\n",
            "2022-04-28 06:11:47,365 - INFO - allennlp.common.params - model.modules.relation.use_classify_mask_pruner = False\n",
            "2022-04-28 06:11:47,365 - INFO - allennlp.common.params - model.modules.relation.use_distance_embeds = True\n",
            "2022-04-28 06:11:47,365 - INFO - allennlp.common.params - model.modules.relation.use_focal_loss = False\n",
            "2022-04-28 06:11:47,366 - INFO - allennlp.common.params - model.modules.relation.use_ner_scores_for_prune = False\n",
            "2022-04-28 06:11:47,366 - INFO - allennlp.common.params - model.modules.relation.use_ope_down_project = False\n",
            "2022-04-28 06:11:47,366 - INFO - allennlp.common.params - model.modules.relation.use_pair_feature_cls = False\n",
            "2022-04-28 06:11:47,366 - INFO - allennlp.common.params - model.modules.relation.use_pair_feature_maxpool = False\n",
            "2022-04-28 06:11:47,366 - INFO - allennlp.common.params - model.modules.relation.use_pair_feature_multiply = False\n",
            "2022-04-28 06:11:47,366 - INFO - allennlp.common.params - model.modules.relation.use_pairwise_down_project = False\n",
            "2022-04-28 06:11:47,367 - INFO - allennlp.common.params - model.modules.relation.use_pruning = True\n",
            "2022-04-28 06:11:47,367 - INFO - allennlp.common.params - model.modules.relation.use_single_pool = False\n",
            "2022-04-28 06:11:47,367 - INFO - allennlp.common.params - model.modules.relation.use_span_loss_for_pruners = False\n",
            "2022-04-28 06:11:47,367 - INFO - allennlp.common.params - model.modules.relation.use_span_pair_aux_task = False\n",
            "2022-04-28 06:11:47,367 - INFO - allennlp.common.params - model.modules.relation.use_span_pair_aux_task_after_prune = False\n",
            "2022-04-28 06:11:47,367 - INFO - allennlp.common.params - model.feature_size = 20\n",
            "2022-04-28 06:11:47,368 - INFO - allennlp.common.params - model.max_span_width = 8\n",
            "2022-04-28 06:11:47,368 - INFO - allennlp.common.params - model.target_task = relation\n",
            "2022-04-28 06:11:47,369 - INFO - allennlp.common.params - model.initializer.regexes.0.1.type = xavier_normal\n",
            "2022-04-28 06:11:47,370 - INFO - allennlp.common.params - model.initializer.regexes.0.1.gain = 1.0\n",
            "2022-04-28 06:11:47,370 - INFO - allennlp.common.params - model.initializer.prevent_regexes = None\n",
            "2022-04-28 06:11:47,371 - INFO - allennlp.common.params - model.module_initializer.regexes.0.1.type = xavier_normal\n",
            "2022-04-28 06:11:47,371 - INFO - allennlp.common.params - model.module_initializer.regexes.0.1.gain = 1.0\n",
            "2022-04-28 06:11:47,372 - INFO - allennlp.common.params - model.module_initializer.regexes.1.1.type = xavier_normal\n",
            "2022-04-28 06:11:47,372 - INFO - allennlp.common.params - model.module_initializer.regexes.1.1.gain = 1.0\n",
            "2022-04-28 06:11:47,372 - INFO - allennlp.common.params - model.module_initializer.prevent_regexes = None\n",
            "2022-04-28 06:11:47,373 - INFO - allennlp.common.params - model.regularizer = None\n",
            "2022-04-28 06:11:47,373 - INFO - allennlp.common.params - model.display_metrics = None\n",
            "2022-04-28 06:11:47,373 - INFO - allennlp.common.params - model.use_ner_embeds = False\n",
            "2022-04-28 06:11:47,373 - INFO - allennlp.common.params - model.span_extractor_type = endpoint\n",
            "2022-04-28 06:11:47,374 - INFO - allennlp.common.params - model.use_double_mix_embedder = False\n",
            "2022-04-28 06:11:47,374 - INFO - allennlp.common.params - model.relation_head_type = proper\n",
            "2022-04-28 06:11:47,374 - INFO - allennlp.common.params - model.use_span_width_embeds = True\n",
            "2022-04-28 06:11:47,374 - INFO - allennlp.common.params - model.use_bilstm_after_embedder = False\n",
            "{'locals': ('use_ner_embeds', False)}\n",
            "{'locals': ('span_extractor_type', 'endpoint')}\n",
            "{'locals': ('use_double_mix_embedder', False)}\n",
            "{'locals': ('relation_head_type', 'proper')}\n",
            "{'locals': ('use_span_width_embeds', True)}\n",
            "2022-04-28 06:11:47,375 - INFO - allennlp.common.params - ner.regularizer = None\n",
            "2022-04-28 06:11:47,376 - INFO - allennlp.common.params - ner.use_bi_affine = False\n",
            "2022-04-28 06:11:47,376 - INFO - allennlp.common.params - ner.neg_class_weight = -1\n",
            "2022-04-28 06:11:47,376 - INFO - allennlp.common.params - ner.use_focal_loss = False\n",
            "2022-04-28 06:11:47,376 - INFO - allennlp.common.params - ner.focal_loss_gamma = 2\n",
            "2022-04-28 06:11:47,376 - INFO - allennlp.common.params - ner.use_double_scorer = False\n",
            "2022-04-28 06:11:47,377 - INFO - allennlp.common.params - ner.use_gold_for_train_prune_scores = False\n",
            "2022-04-28 06:11:47,377 - INFO - allennlp.common.params - ner.use_single_pool = False\n",
            "2022-04-28 06:11:47,377 - INFO - allennlp.common.params - ner.name = ner_labels\n",
            "{'ner_loss_fn': CrossEntropyLoss()}\n",
            "2022-04-28 06:11:47,383 - INFO - allennlp.common.params - relation.regularizer = None\n",
            "2022-04-28 06:11:47,384 - INFO - allennlp.common.params - relation.serialization_dir = None\n",
            "2022-04-28 06:11:47,384 - INFO - allennlp.common.params - relation.spans_per_word = 0.5\n",
            "2022-04-28 06:11:47,384 - INFO - allennlp.common.params - relation.positive_label_weight = 1.0\n",
            "2022-04-28 06:11:47,384 - INFO - allennlp.common.params - relation.use_distance_embeds = True\n",
            "2022-04-28 06:11:47,385 - INFO - allennlp.common.params - relation.use_pair_feature_maxpool = False\n",
            "2022-04-28 06:11:47,385 - INFO - allennlp.common.params - relation.use_pair_feature_cls = False\n",
            "2022-04-28 06:11:47,385 - INFO - allennlp.common.params - relation.use_bi_affine_classifier = False\n",
            "2022-04-28 06:11:47,385 - INFO - allennlp.common.params - relation.neg_class_weight = -1\n",
            "2022-04-28 06:11:47,386 - INFO - allennlp.common.params - relation.span_length_loss_weight_gamma = 0\n",
            "2022-04-28 06:11:47,386 - INFO - allennlp.common.params - relation.use_bag_pair_scorer = False\n",
            "2022-04-28 06:11:47,386 - INFO - allennlp.common.params - relation.use_bi_affine_v2 = False\n",
            "2022-04-28 06:11:47,386 - INFO - allennlp.common.params - relation.use_pruning = True\n",
            "2022-04-28 06:11:47,387 - INFO - allennlp.common.params - relation.use_single_pool = False\n",
            "{'unused_keys': dict_keys(['focal_loss_gamma', 'use_bi_affine_pruner', 'use_classify_mask_pruner', 'use_focal_loss', 'use_ner_scores_for_prune', 'use_ope_down_project', 'use_pair_feature_multiply', 'use_pairwise_down_project', 'use_span_loss_for_pruners', 'use_span_pair_aux_task', 'use_span_pair_aux_task_after_prune'])}\n",
            "{'locals': {'self': ProperRelationExtractor(), 'make_feedforward': <function SpanModel.__init__.<locals>.make_feedforward at 0x7f62a6013050>, 'span_emb_dim': 1556, 'feature_size': 20, 'spans_per_word': 0.5, 'positive_label_weight': 1.0, 'regularizer': None, 'use_distance_embeds': True, 'use_pair_feature_maxpool': False, 'use_pair_feature_cls': False, 'use_bi_affine_classifier': False, 'neg_class_weight': -1, 'span_length_loss_weight_gamma': 0, 'use_bag_pair_scorer': False, 'use_bi_affine_v2': False, 'use_pruning': True, 'use_single_pool': False, 'kwargs': {'focal_loss_gamma': 2, 'use_bi_affine_pruner': False, 'use_classify_mask_pruner': False, 'use_focal_loss': False, 'use_ner_scores_for_prune': False, 'use_ope_down_project': False, 'use_pair_feature_multiply': False, 'use_pairwise_down_project': False, 'use_span_loss_for_pruners': False, 'use_span_pair_aux_task': False, 'use_span_pair_aux_task_after_prune': False}, 'vocab': Vocabulary with namespaces:  None__ner_labels, Size: 3 || None__tag_labels, Size: 9 || None__relation_labels, Size: 3 || Non Padded Namespaces: {'*labels', '*tags'}, '__class__': <class 'span_model.models.relation_proper.ProperRelationExtractor'>}}\n",
            "{'token_emb_dim': 768, 'span_emb_dim': 1556, 'relation_scorer_dim': 3240}\n",
            "{'relation_loss_fn': CrossEntropyLoss()}\n",
            "2022-04-28 06:11:47,407 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2022-04-28 06:11:47,408 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.0._module._linear_layers.0.weight using .*weight initializer\n",
            "2022-04-28 06:11:47,412 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.0._module._linear_layers.1.weight using .*weight initializer\n",
            "2022-04-28 06:11:47,413 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.1._module.weight using .*weight initializer\n",
            "2022-04-28 06:11:47,413 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight_matrix\n",
            "2022-04-28 06:11:47,414 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2022-04-28 06:11:47,414 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.0._module._linear_layers.0.bias\n",
            "2022-04-28 06:11:47,414 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.0._module._linear_layers.1.bias\n",
            "2022-04-28 06:11:47,414 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.1._module.bias\n",
            "2022-04-28 06:11:47,414 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2022-04-28 06:11:47,415 - INFO - allennlp.nn.initializers - Initializing d_embedder.embedder.weight using .*weight initializer\n",
            "2022-04-28 06:11:47,415 - INFO - allennlp.nn.initializers - Initializing _relation_feedforwards.None__relation_labels._linear_layers.0.weight using .*weight initializer\n",
            "2022-04-28 06:11:47,422 - INFO - allennlp.nn.initializers - Initializing _relation_feedforwards.None__relation_labels._linear_layers.1.weight using .*weight initializer\n",
            "2022-04-28 06:11:47,423 - INFO - allennlp.nn.initializers - Initializing _relation_scorers.None__relation_labels.weight using .*weight initializer\n",
            "2022-04-28 06:11:47,423 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight_matrix\n",
            "2022-04-28 06:11:47,424 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2022-04-28 06:11:47,424 - INFO - allennlp.nn.initializers -    _relation_feedforwards.None__relation_labels._linear_layers.0.bias\n",
            "2022-04-28 06:11:47,424 - INFO - allennlp.nn.initializers -    _relation_feedforwards.None__relation_labels._linear_layers.1.bias\n",
            "2022-04-28 06:11:47,424 - INFO - allennlp.nn.initializers -    _relation_scorers.None__relation_labels.bias\n",
            "2022-04-28 06:11:47,425 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2022-04-28 06:11:47,425 - INFO - allennlp.nn.initializers - Initializing _endpoint_span_extractor._span_width_embedding.weight using _span_width_embedding.weight initializer\n",
            "2022-04-28 06:11:47,429 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2022-04-28 06:11:47,429 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias\n",
            "2022-04-28 06:11:47,430 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight\n",
            "2022-04-28 06:11:47,430 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight\n",
            "2022-04-28 06:11:47,430 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight\n",
            "2022-04-28 06:11:47,430 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight\n",
            "2022-04-28 06:11:47,430 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "2022-04-28 06:11:47,431 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "2022-04-28 06:11:47,431 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias\n",
            "2022-04-28 06:11:47,431 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight\n",
            "2022-04-28 06:11:47,431 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias\n",
            "2022-04-28 06:11:47,431 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight\n",
            "2022-04-28 06:11:47,432 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias\n",
            "2022-04-28 06:11:47,432 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight\n",
            "2022-04-28 06:11:47,432 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias\n",
            "2022-04-28 06:11:47,432 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight\n",
            "2022-04-28 06:11:47,432 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias\n",
            "2022-04-28 06:11:47,432 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight\n",
            "2022-04-28 06:11:47,433 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias\n",
            "2022-04-28 06:11:47,433 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight\n",
            "2022-04-28 06:11:47,433 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias\n",
            "2022-04-28 06:11:47,433 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight\n",
            "2022-04-28 06:11:47,433 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "2022-04-28 06:11:47,434 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "2022-04-28 06:11:47,434 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias\n",
            "2022-04-28 06:11:47,434 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight\n",
            "2022-04-28 06:11:47,434 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias\n",
            "2022-04-28 06:11:47,434 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight\n",
            "2022-04-28 06:11:47,435 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias\n",
            "2022-04-28 06:11:47,435 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight\n",
            "2022-04-28 06:11:47,435 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias\n",
            "2022-04-28 06:11:47,435 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight\n",
            "2022-04-28 06:11:47,435 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias\n",
            "2022-04-28 06:11:47,436 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight\n",
            "2022-04-28 06:11:47,436 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias\n",
            "2022-04-28 06:11:47,436 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight\n",
            "2022-04-28 06:11:47,436 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias\n",
            "2022-04-28 06:11:47,436 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight\n",
            "2022-04-28 06:11:47,436 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "2022-04-28 06:11:47,437 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "2022-04-28 06:11:47,437 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias\n",
            "2022-04-28 06:11:47,437 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight\n",
            "2022-04-28 06:11:47,437 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias\n",
            "2022-04-28 06:11:47,437 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight\n",
            "2022-04-28 06:11:47,437 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias\n",
            "2022-04-28 06:11:47,438 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight\n",
            "2022-04-28 06:11:47,438 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias\n",
            "2022-04-28 06:11:47,438 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight\n",
            "2022-04-28 06:11:47,438 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias\n",
            "2022-04-28 06:11:47,438 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight\n",
            "2022-04-28 06:11:47,439 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias\n",
            "2022-04-28 06:11:47,439 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight\n",
            "2022-04-28 06:11:47,439 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias\n",
            "2022-04-28 06:11:47,439 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight\n",
            "2022-04-28 06:11:47,439 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "2022-04-28 06:11:47,439 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "2022-04-28 06:11:47,440 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias\n",
            "2022-04-28 06:11:47,440 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight\n",
            "2022-04-28 06:11:47,440 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias\n",
            "2022-04-28 06:11:47,440 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight\n",
            "2022-04-28 06:11:47,440 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias\n",
            "2022-04-28 06:11:47,440 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight\n",
            "2022-04-28 06:11:47,441 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias\n",
            "2022-04-28 06:11:47,441 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight\n",
            "2022-04-28 06:11:47,441 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias\n",
            "2022-04-28 06:11:47,441 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight\n",
            "2022-04-28 06:11:47,441 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias\n",
            "2022-04-28 06:11:47,442 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight\n",
            "2022-04-28 06:11:47,442 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias\n",
            "2022-04-28 06:11:47,442 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight\n",
            "2022-04-28 06:11:47,442 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "2022-04-28 06:11:47,442 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "2022-04-28 06:11:47,442 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias\n",
            "2022-04-28 06:11:47,443 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight\n",
            "2022-04-28 06:11:47,443 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias\n",
            "2022-04-28 06:11:47,443 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight\n",
            "2022-04-28 06:11:47,443 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias\n",
            "2022-04-28 06:11:47,443 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight\n",
            "2022-04-28 06:11:47,443 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias\n",
            "2022-04-28 06:11:47,444 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight\n",
            "2022-04-28 06:11:47,444 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias\n",
            "2022-04-28 06:11:47,444 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight\n",
            "2022-04-28 06:11:47,444 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias\n",
            "2022-04-28 06:11:47,444 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight\n",
            "2022-04-28 06:11:47,444 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias\n",
            "2022-04-28 06:11:47,445 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight\n",
            "2022-04-28 06:11:47,445 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "2022-04-28 06:11:47,445 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "2022-04-28 06:11:47,445 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias\n",
            "2022-04-28 06:11:47,445 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight\n",
            "2022-04-28 06:11:47,445 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias\n",
            "2022-04-28 06:11:47,446 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight\n",
            "2022-04-28 06:11:47,446 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias\n",
            "2022-04-28 06:11:47,446 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight\n",
            "2022-04-28 06:11:47,446 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias\n",
            "2022-04-28 06:11:47,447 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight\n",
            "2022-04-28 06:11:47,447 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias\n",
            "2022-04-28 06:11:47,447 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight\n",
            "2022-04-28 06:11:47,447 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias\n",
            "2022-04-28 06:11:47,447 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight\n",
            "2022-04-28 06:11:47,448 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias\n",
            "2022-04-28 06:11:47,448 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight\n",
            "2022-04-28 06:11:47,448 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "2022-04-28 06:11:47,449 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "2022-04-28 06:11:47,449 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias\n",
            "2022-04-28 06:11:47,449 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight\n",
            "2022-04-28 06:11:47,449 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias\n",
            "2022-04-28 06:11:47,450 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight\n",
            "2022-04-28 06:11:47,450 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias\n",
            "2022-04-28 06:11:47,450 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight\n",
            "2022-04-28 06:11:47,450 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias\n",
            "2022-04-28 06:11:47,451 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight\n",
            "2022-04-28 06:11:47,451 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias\n",
            "2022-04-28 06:11:47,451 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight\n",
            "2022-04-28 06:11:47,452 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias\n",
            "2022-04-28 06:11:47,452 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight\n",
            "2022-04-28 06:11:47,452 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias\n",
            "2022-04-28 06:11:47,452 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight\n",
            "2022-04-28 06:11:47,452 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "2022-04-28 06:11:47,453 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "2022-04-28 06:11:47,453 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias\n",
            "2022-04-28 06:11:47,453 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight\n",
            "2022-04-28 06:11:47,453 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias\n",
            "2022-04-28 06:11:47,453 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight\n",
            "2022-04-28 06:11:47,454 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias\n",
            "2022-04-28 06:11:47,454 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight\n",
            "2022-04-28 06:11:47,454 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias\n",
            "2022-04-28 06:11:47,455 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight\n",
            "2022-04-28 06:11:47,455 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias\n",
            "2022-04-28 06:11:47,455 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight\n",
            "2022-04-28 06:11:47,455 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias\n",
            "2022-04-28 06:11:47,455 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight\n",
            "2022-04-28 06:11:47,456 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias\n",
            "2022-04-28 06:11:47,456 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight\n",
            "2022-04-28 06:11:47,456 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "2022-04-28 06:11:47,457 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "2022-04-28 06:11:47,457 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias\n",
            "2022-04-28 06:11:47,457 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight\n",
            "2022-04-28 06:11:47,457 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias\n",
            "2022-04-28 06:11:47,457 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight\n",
            "2022-04-28 06:11:47,458 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias\n",
            "2022-04-28 06:11:47,458 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight\n",
            "2022-04-28 06:11:47,458 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias\n",
            "2022-04-28 06:11:47,458 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight\n",
            "2022-04-28 06:11:47,459 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias\n",
            "2022-04-28 06:11:47,459 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight\n",
            "2022-04-28 06:11:47,459 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias\n",
            "2022-04-28 06:11:47,459 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight\n",
            "2022-04-28 06:11:47,460 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias\n",
            "2022-04-28 06:11:47,460 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight\n",
            "2022-04-28 06:11:47,460 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "2022-04-28 06:11:47,460 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "2022-04-28 06:11:47,460 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias\n",
            "2022-04-28 06:11:47,461 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight\n",
            "2022-04-28 06:11:47,461 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias\n",
            "2022-04-28 06:11:47,461 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight\n",
            "2022-04-28 06:11:47,461 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias\n",
            "2022-04-28 06:11:47,461 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight\n",
            "2022-04-28 06:11:47,462 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias\n",
            "2022-04-28 06:11:47,462 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight\n",
            "2022-04-28 06:11:47,463 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias\n",
            "2022-04-28 06:11:47,463 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight\n",
            "2022-04-28 06:11:47,463 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias\n",
            "2022-04-28 06:11:47,463 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight\n",
            "2022-04-28 06:11:47,463 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias\n",
            "2022-04-28 06:11:47,463 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight\n",
            "2022-04-28 06:11:47,464 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "2022-04-28 06:11:47,464 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "2022-04-28 06:11:47,464 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias\n",
            "2022-04-28 06:11:47,464 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight\n",
            "2022-04-28 06:11:47,465 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias\n",
            "2022-04-28 06:11:47,465 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight\n",
            "2022-04-28 06:11:47,465 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias\n",
            "2022-04-28 06:11:47,465 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight\n",
            "2022-04-28 06:11:47,466 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias\n",
            "2022-04-28 06:11:47,466 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight\n",
            "2022-04-28 06:11:47,466 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias\n",
            "2022-04-28 06:11:47,466 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight\n",
            "2022-04-28 06:11:47,467 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias\n",
            "2022-04-28 06:11:47,467 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight\n",
            "2022-04-28 06:11:47,467 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias\n",
            "2022-04-28 06:11:47,468 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight\n",
            "2022-04-28 06:11:47,468 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "2022-04-28 06:11:47,468 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "2022-04-28 06:11:47,469 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias\n",
            "2022-04-28 06:11:47,469 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight\n",
            "2022-04-28 06:11:47,469 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias\n",
            "2022-04-28 06:11:47,469 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight\n",
            "2022-04-28 06:11:47,470 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias\n",
            "2022-04-28 06:11:47,470 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight\n",
            "2022-04-28 06:11:47,470 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias\n",
            "2022-04-28 06:11:47,471 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight\n",
            "2022-04-28 06:11:47,471 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias\n",
            "2022-04-28 06:11:47,471 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight\n",
            "2022-04-28 06:11:47,472 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias\n",
            "2022-04-28 06:11:47,472 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight\n",
            "2022-04-28 06:11:47,472 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias\n",
            "2022-04-28 06:11:47,472 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight\n",
            "2022-04-28 06:11:47,472 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias\n",
            "2022-04-28 06:11:47,473 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight\n",
            "2022-04-28 06:11:47,473 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.bias\n",
            "2022-04-28 06:11:47,473 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.weight\n",
            "2022-04-28 06:11:47,474 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.bias\n",
            "2022-04-28 06:11:47,474 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.weight\n",
            "2022-04-28 06:11:47,474 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.1._module.bias\n",
            "2022-04-28 06:11:47,475 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.1._module.weight\n",
            "2022-04-28 06:11:47,475 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.0.bias\n",
            "2022-04-28 06:11:47,475 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.0.weight\n",
            "2022-04-28 06:11:47,476 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.1.bias\n",
            "2022-04-28 06:11:47,476 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.1.weight\n",
            "2022-04-28 06:11:47,476 - INFO - allennlp.nn.initializers -    _relation._relation_scorers.None__relation_labels.bias\n",
            "2022-04-28 06:11:47,476 - INFO - allennlp.nn.initializers -    _relation._relation_scorers.None__relation_labels.weight\n",
            "2022-04-28 06:11:47,477 - INFO - allennlp.nn.initializers -    _relation.d_embedder.embedder.weight\n",
            "2022-04-28 06:11:47,479 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader\n",
            "2022-04-28 06:11:47,479 - INFO - allennlp.common.params - data_loader.batch_size = 1\n",
            "2022-04-28 06:11:47,480 - INFO - allennlp.common.params - data_loader.shuffle = False\n",
            "2022-04-28 06:11:47,480 - INFO - allennlp.common.params - data_loader.batch_sampler = None\n",
            "2022-04-28 06:11:47,481 - INFO - allennlp.common.params - data_loader.num_workers = 0\n",
            "2022-04-28 06:11:47,481 - INFO - allennlp.common.params - data_loader.pin_memory = False\n",
            "2022-04-28 06:11:47,482 - INFO - allennlp.common.params - data_loader.drop_last = False\n",
            "2022-04-28 06:11:47,482 - INFO - allennlp.common.params - data_loader.timeout = 0\n",
            "2022-04-28 06:11:47,482 - INFO - allennlp.common.params - data_loader.worker_init_fn = None\n",
            "2022-04-28 06:11:47,483 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None\n",
            "2022-04-28 06:11:47,483 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None\n",
            "2022-04-28 06:11:47,483 - INFO - allennlp.common.params - data_loader.sampler.type = random\n",
            "2022-04-28 06:11:47,484 - INFO - allennlp.common.params - data_loader.sampler.replacement = False\n",
            "2022-04-28 06:11:47,484 - INFO - allennlp.common.params - data_loader.sampler.num_samples = None\n",
            "2022-04-28 06:11:47,486 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader\n",
            "2022-04-28 06:11:47,486 - INFO - allennlp.common.params - data_loader.batch_size = 1\n",
            "2022-04-28 06:11:47,487 - INFO - allennlp.common.params - data_loader.shuffle = False\n",
            "2022-04-28 06:11:47,487 - INFO - allennlp.common.params - data_loader.batch_sampler = None\n",
            "2022-04-28 06:11:47,487 - INFO - allennlp.common.params - data_loader.num_workers = 0\n",
            "2022-04-28 06:11:47,488 - INFO - allennlp.common.params - data_loader.pin_memory = False\n",
            "2022-04-28 06:11:47,488 - INFO - allennlp.common.params - data_loader.drop_last = False\n",
            "2022-04-28 06:11:47,489 - INFO - allennlp.common.params - data_loader.timeout = 0\n",
            "2022-04-28 06:11:47,489 - INFO - allennlp.common.params - data_loader.worker_init_fn = None\n",
            "2022-04-28 06:11:47,489 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None\n",
            "2022-04-28 06:11:47,490 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None\n",
            "2022-04-28 06:11:47,490 - INFO - allennlp.common.params - data_loader.sampler.type = random\n",
            "2022-04-28 06:11:47,491 - INFO - allennlp.common.params - data_loader.sampler.replacement = False\n",
            "2022-04-28 06:11:47,491 - INFO - allennlp.common.params - data_loader.sampler.num_samples = None\n",
            "2022-04-28 06:11:47,492 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader\n",
            "2022-04-28 06:11:47,493 - INFO - allennlp.common.params - data_loader.batch_size = 1\n",
            "2022-04-28 06:11:47,493 - INFO - allennlp.common.params - data_loader.shuffle = False\n",
            "2022-04-28 06:11:47,494 - INFO - allennlp.common.params - data_loader.batch_sampler = None\n",
            "2022-04-28 06:11:47,494 - INFO - allennlp.common.params - data_loader.num_workers = 0\n",
            "2022-04-28 06:11:47,494 - INFO - allennlp.common.params - data_loader.pin_memory = False\n",
            "2022-04-28 06:11:47,494 - INFO - allennlp.common.params - data_loader.drop_last = False\n",
            "2022-04-28 06:11:47,494 - INFO - allennlp.common.params - data_loader.timeout = 0\n",
            "2022-04-28 06:11:47,494 - INFO - allennlp.common.params - data_loader.worker_init_fn = None\n",
            "2022-04-28 06:11:47,495 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None\n",
            "2022-04-28 06:11:47,495 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None\n",
            "2022-04-28 06:11:47,495 - INFO - allennlp.common.params - data_loader.sampler.type = random\n",
            "2022-04-28 06:11:47,495 - INFO - allennlp.common.params - data_loader.sampler.replacement = False\n",
            "2022-04-28 06:11:47,496 - INFO - allennlp.common.params - data_loader.sampler.num_samples = None\n",
            "2022-04-28 06:11:47,496 - INFO - allennlp.common.params - trainer.type = gradient_descent\n",
            "2022-04-28 06:11:47,497 - INFO - allennlp.common.params - trainer.patience = None\n",
            "2022-04-28 06:11:47,497 - INFO - allennlp.common.params - trainer.validation_metric = +MEAN__relation_f1\n",
            "2022-04-28 06:11:47,497 - INFO - allennlp.common.params - trainer.num_epochs = 10\n",
            "2022-04-28 06:11:47,497 - INFO - allennlp.common.params - trainer.cuda_device = 0\n",
            "2022-04-28 06:11:47,498 - INFO - allennlp.common.params - trainer.grad_norm = 5\n",
            "2022-04-28 06:11:47,498 - INFO - allennlp.common.params - trainer.grad_clipping = None\n",
            "2022-04-28 06:11:47,498 - INFO - allennlp.common.params - trainer.distributed = False\n",
            "2022-04-28 06:11:47,499 - INFO - allennlp.common.params - trainer.world_size = 1\n",
            "2022-04-28 06:11:47,499 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 1\n",
            "2022-04-28 06:11:47,499 - INFO - allennlp.common.params - trainer.use_amp = False\n",
            "2022-04-28 06:11:47,500 - INFO - allennlp.common.params - trainer.no_grad = None\n",
            "2022-04-28 06:11:47,501 - INFO - allennlp.common.params - trainer.momentum_scheduler = None\n",
            "2022-04-28 06:11:47,501 - INFO - allennlp.common.params - trainer.tensorboard_writer = <allennlp.common.lazy.Lazy object at 0x7f62aabcc8d0>\n",
            "2022-04-28 06:11:47,501 - INFO - allennlp.common.params - trainer.moving_average = None\n",
            "2022-04-28 06:11:47,502 - INFO - allennlp.common.params - trainer.batch_callbacks = None\n",
            "2022-04-28 06:11:47,502 - INFO - allennlp.common.params - trainer.epoch_callbacks = None\n",
            "2022-04-28 06:11:47,503 - INFO - allennlp.common.params - trainer.end_callbacks = None\n",
            "2022-04-28 06:11:47,503 - INFO - allennlp.common.params - trainer.trainer_callbacks = None\n",
            "2022-04-28 06:11:49,540 - INFO - allennlp.common.params - trainer.optimizer.type = adamw\n",
            "2022-04-28 06:11:49,541 - INFO - allennlp.common.params - trainer.optimizer.lr = 0.001\n",
            "2022-04-28 06:11:49,542 - INFO - allennlp.common.params - trainer.optimizer.betas = (0.9, 0.999)\n",
            "2022-04-28 06:11:49,542 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-08\n",
            "2022-04-28 06:11:49,542 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0\n",
            "2022-04-28 06:11:49,542 - INFO - allennlp.common.params - trainer.optimizer.amsgrad = False\n",
            "2022-04-28 06:11:49,544 - INFO - allennlp.training.optimizers - Done constructing parameter groups.\n",
            "2022-04-28 06:11:49,544 - INFO - allennlp.training.optimizers - Group 0: ['_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight'], {'finetune': True, 'lr': 5e-05, 'weight_decay': 0.01}\n",
            "2022-04-28 06:11:49,545 - INFO - allennlp.training.optimizers - Group 1: [], {'lr': 0.01}\n",
            "2022-04-28 06:11:49,545 - INFO - allennlp.training.optimizers - Group 2: ['_ner._ner_scorers.None__ner_labels.1._module.weight', '_ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.bias', '_relation._relation_feedforwards.None__relation_labels._linear_layers.0.bias', '_relation._relation_scorers.None__relation_labels.weight', '_relation._relation_scorers.None__relation_labels.bias', '_relation._relation_feedforwards.None__relation_labels._linear_layers.1.bias', '_ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.weight', '_endpoint_span_extractor._span_width_embedding.weight', '_ner._ner_scorers.None__ner_labels.1._module.bias', '_relation.d_embedder.embedder.weight', '_relation._relation_feedforwards.None__relation_labels._linear_layers.0.weight', '_relation._relation_feedforwards.None__relation_labels._linear_layers.1.weight', '_ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.bias', '_ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.weight'], {}\n",
            "2022-04-28 06:11:49,545 - WARNING - allennlp.training.optimizers - When constructing parameter groups, scalar_parameters does not match any parameter name\n",
            "2022-04-28 06:11:49,546 - INFO - allennlp.training.optimizers - Number of trainable parameters: 110249737\n",
            "2022-04-28 06:11:49,549 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):\n",
            "2022-04-28 06:11:49,551 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):\n",
            "2022-04-28 06:11:49,552 - INFO - allennlp.common.util - _endpoint_span_extractor._span_width_embedding.weight\n",
            "2022-04-28 06:11:49,552 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight\n",
            "2022-04-28 06:11:49,552 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight\n",
            "2022-04-28 06:11:49,552 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight\n",
            "2022-04-28 06:11:49,552 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight\n",
            "2022-04-28 06:11:49,553 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias\n",
            "2022-04-28 06:11:49,553 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight\n",
            "2022-04-28 06:11:49,553 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias\n",
            "2022-04-28 06:11:49,553 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight\n",
            "2022-04-28 06:11:49,554 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias\n",
            "2022-04-28 06:11:49,554 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight\n",
            "2022-04-28 06:11:49,554 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias\n",
            "2022-04-28 06:11:49,554 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight\n",
            "2022-04-28 06:11:49,555 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias\n",
            "2022-04-28 06:11:49,574 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "2022-04-28 06:11:49,575 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "2022-04-28 06:11:49,575 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight\n",
            "2022-04-28 06:11:49,575 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias\n",
            "2022-04-28 06:11:49,575 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight\n",
            "2022-04-28 06:11:49,575 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias\n",
            "2022-04-28 06:11:49,575 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight\n",
            "2022-04-28 06:11:49,575 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias\n",
            "2022-04-28 06:11:49,576 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight\n",
            "2022-04-28 06:11:49,576 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias\n",
            "2022-04-28 06:11:49,576 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight\n",
            "2022-04-28 06:11:49,576 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias\n",
            "2022-04-28 06:11:49,576 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight\n",
            "2022-04-28 06:11:49,576 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias\n",
            "2022-04-28 06:11:49,576 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight\n",
            "2022-04-28 06:11:49,576 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias\n",
            "2022-04-28 06:11:49,577 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "2022-04-28 06:11:49,577 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "2022-04-28 06:11:49,577 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight\n",
            "2022-04-28 06:11:49,577 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias\n",
            "2022-04-28 06:11:49,577 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight\n",
            "2022-04-28 06:11:49,577 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias\n",
            "2022-04-28 06:11:49,577 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight\n",
            "2022-04-28 06:11:49,578 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias\n",
            "2022-04-28 06:11:49,578 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight\n",
            "2022-04-28 06:11:49,578 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias\n",
            "2022-04-28 06:11:49,578 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight\n",
            "2022-04-28 06:11:49,578 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias\n",
            "2022-04-28 06:11:49,578 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight\n",
            "2022-04-28 06:11:49,580 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias\n",
            "2022-04-28 06:11:49,580 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight\n",
            "2022-04-28 06:11:49,580 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias\n",
            "2022-04-28 06:11:49,580 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "2022-04-28 06:11:49,580 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "2022-04-28 06:11:49,581 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight\n",
            "2022-04-28 06:11:49,581 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias\n",
            "2022-04-28 06:11:49,581 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight\n",
            "2022-04-28 06:11:49,581 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias\n",
            "2022-04-28 06:11:49,581 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight\n",
            "2022-04-28 06:11:49,581 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias\n",
            "2022-04-28 06:11:49,582 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight\n",
            "2022-04-28 06:11:49,582 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias\n",
            "2022-04-28 06:11:49,582 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight\n",
            "2022-04-28 06:11:49,582 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias\n",
            "2022-04-28 06:11:49,582 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight\n",
            "2022-04-28 06:11:49,583 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias\n",
            "2022-04-28 06:11:49,583 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight\n",
            "2022-04-28 06:11:49,583 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias\n",
            "2022-04-28 06:11:49,583 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "2022-04-28 06:11:49,583 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "2022-04-28 06:11:49,584 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight\n",
            "2022-04-28 06:11:49,584 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias\n",
            "2022-04-28 06:11:49,584 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight\n",
            "2022-04-28 06:11:49,584 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias\n",
            "2022-04-28 06:11:49,586 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight\n",
            "2022-04-28 06:11:49,586 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias\n",
            "2022-04-28 06:11:49,586 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight\n",
            "2022-04-28 06:11:49,587 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias\n",
            "2022-04-28 06:11:49,587 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight\n",
            "2022-04-28 06:11:49,587 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias\n",
            "2022-04-28 06:11:49,587 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight\n",
            "2022-04-28 06:11:49,588 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias\n",
            "2022-04-28 06:11:49,588 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight\n",
            "2022-04-28 06:11:49,588 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias\n",
            "2022-04-28 06:11:49,588 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "2022-04-28 06:11:49,588 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "2022-04-28 06:11:49,597 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight\n",
            "2022-04-28 06:11:49,597 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias\n",
            "2022-04-28 06:11:49,597 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight\n",
            "2022-04-28 06:11:49,597 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias\n",
            "2022-04-28 06:11:49,598 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight\n",
            "2022-04-28 06:11:49,598 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias\n",
            "2022-04-28 06:11:49,598 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight\n",
            "2022-04-28 06:11:49,598 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias\n",
            "2022-04-28 06:11:49,598 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight\n",
            "2022-04-28 06:11:49,601 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias\n",
            "2022-04-28 06:11:49,601 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight\n",
            "2022-04-28 06:11:49,601 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias\n",
            "2022-04-28 06:11:49,601 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight\n",
            "2022-04-28 06:11:49,601 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias\n",
            "2022-04-28 06:11:49,602 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "2022-04-28 06:11:49,602 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "2022-04-28 06:11:49,602 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight\n",
            "2022-04-28 06:11:49,602 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias\n",
            "2022-04-28 06:11:49,603 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight\n",
            "2022-04-28 06:11:49,603 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias\n",
            "2022-04-28 06:11:49,603 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight\n",
            "2022-04-28 06:11:49,603 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias\n",
            "2022-04-28 06:11:49,603 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight\n",
            "2022-04-28 06:11:49,603 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias\n",
            "2022-04-28 06:11:49,604 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight\n",
            "2022-04-28 06:11:49,604 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias\n",
            "2022-04-28 06:11:49,604 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight\n",
            "2022-04-28 06:11:49,604 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias\n",
            "2022-04-28 06:11:49,604 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight\n",
            "2022-04-28 06:11:49,605 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias\n",
            "2022-04-28 06:11:49,605 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "2022-04-28 06:11:49,605 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "2022-04-28 06:11:49,605 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight\n",
            "2022-04-28 06:11:49,605 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias\n",
            "2022-04-28 06:11:49,606 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight\n",
            "2022-04-28 06:11:49,606 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias\n",
            "2022-04-28 06:11:49,606 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight\n",
            "2022-04-28 06:11:49,606 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias\n",
            "2022-04-28 06:11:49,606 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight\n",
            "2022-04-28 06:11:49,607 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias\n",
            "2022-04-28 06:11:49,607 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight\n",
            "2022-04-28 06:11:49,607 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias\n",
            "2022-04-28 06:11:49,607 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight\n",
            "2022-04-28 06:11:49,608 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias\n",
            "2022-04-28 06:11:49,608 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight\n",
            "2022-04-28 06:11:49,608 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias\n",
            "2022-04-28 06:11:49,608 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "2022-04-28 06:11:49,608 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "2022-04-28 06:11:49,609 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight\n",
            "2022-04-28 06:11:49,609 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias\n",
            "2022-04-28 06:11:49,609 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight\n",
            "2022-04-28 06:11:49,609 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias\n",
            "2022-04-28 06:11:49,609 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight\n",
            "2022-04-28 06:11:49,610 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias\n",
            "2022-04-28 06:11:49,610 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight\n",
            "2022-04-28 06:11:49,610 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias\n",
            "2022-04-28 06:11:49,610 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight\n",
            "2022-04-28 06:11:49,610 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias\n",
            "2022-04-28 06:11:49,611 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight\n",
            "2022-04-28 06:11:49,611 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias\n",
            "2022-04-28 06:11:49,611 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight\n",
            "2022-04-28 06:11:49,611 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias\n",
            "2022-04-28 06:11:49,611 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "2022-04-28 06:11:49,612 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "2022-04-28 06:11:49,612 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight\n",
            "2022-04-28 06:11:49,612 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias\n",
            "2022-04-28 06:11:49,612 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight\n",
            "2022-04-28 06:11:49,613 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias\n",
            "2022-04-28 06:11:49,613 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight\n",
            "2022-04-28 06:11:49,613 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias\n",
            "2022-04-28 06:11:49,613 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight\n",
            "2022-04-28 06:11:49,613 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias\n",
            "2022-04-28 06:11:49,614 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight\n",
            "2022-04-28 06:11:49,614 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias\n",
            "2022-04-28 06:11:49,614 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight\n",
            "2022-04-28 06:11:49,614 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias\n",
            "2022-04-28 06:11:49,614 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight\n",
            "2022-04-28 06:11:49,615 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias\n",
            "2022-04-28 06:11:49,615 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "2022-04-28 06:11:49,615 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "2022-04-28 06:11:49,615 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight\n",
            "2022-04-28 06:11:49,615 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias\n",
            "2022-04-28 06:11:49,616 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight\n",
            "2022-04-28 06:11:49,616 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias\n",
            "2022-04-28 06:11:49,616 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight\n",
            "2022-04-28 06:11:49,616 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias\n",
            "2022-04-28 06:11:49,616 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight\n",
            "2022-04-28 06:11:49,617 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias\n",
            "2022-04-28 06:11:49,617 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight\n",
            "2022-04-28 06:11:49,617 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias\n",
            "2022-04-28 06:11:49,617 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight\n",
            "2022-04-28 06:11:49,618 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias\n",
            "2022-04-28 06:11:49,618 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight\n",
            "2022-04-28 06:11:49,618 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias\n",
            "2022-04-28 06:11:49,618 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "2022-04-28 06:11:49,618 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "2022-04-28 06:11:49,619 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight\n",
            "2022-04-28 06:11:49,619 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias\n",
            "2022-04-28 06:11:49,619 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight\n",
            "2022-04-28 06:11:49,619 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias\n",
            "2022-04-28 06:11:49,619 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight\n",
            "2022-04-28 06:11:49,620 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias\n",
            "2022-04-28 06:11:49,620 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight\n",
            "2022-04-28 06:11:49,620 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias\n",
            "2022-04-28 06:11:49,620 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight\n",
            "2022-04-28 06:11:49,620 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias\n",
            "2022-04-28 06:11:49,621 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight\n",
            "2022-04-28 06:11:49,621 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias\n",
            "2022-04-28 06:11:49,621 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight\n",
            "2022-04-28 06:11:49,621 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias\n",
            "2022-04-28 06:11:49,622 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "2022-04-28 06:11:49,622 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "2022-04-28 06:11:49,622 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight\n",
            "2022-04-28 06:11:49,622 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias\n",
            "2022-04-28 06:11:49,622 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight\n",
            "2022-04-28 06:11:49,623 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias\n",
            "2022-04-28 06:11:49,623 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight\n",
            "2022-04-28 06:11:49,623 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias\n",
            "2022-04-28 06:11:49,623 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight\n",
            "2022-04-28 06:11:49,623 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias\n",
            "2022-04-28 06:11:49,624 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.weight\n",
            "2022-04-28 06:11:49,624 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.bias\n",
            "2022-04-28 06:11:49,624 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.weight\n",
            "2022-04-28 06:11:49,624 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.bias\n",
            "2022-04-28 06:11:49,625 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.1._module.weight\n",
            "2022-04-28 06:11:49,625 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.1._module.bias\n",
            "2022-04-28 06:11:49,625 - INFO - allennlp.common.util - _relation.d_embedder.embedder.weight\n",
            "2022-04-28 06:11:49,627 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.0.weight\n",
            "2022-04-28 06:11:49,628 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.0.bias\n",
            "2022-04-28 06:11:49,628 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.1.weight\n",
            "2022-04-28 06:11:49,628 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.1.bias\n",
            "2022-04-28 06:11:49,628 - INFO - allennlp.common.util - _relation._relation_scorers.None__relation_labels.weight\n",
            "2022-04-28 06:11:49,628 - INFO - allennlp.common.util - _relation._relation_scorers.None__relation_labels.bias\n",
            "2022-04-28 06:11:49,629 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.type = slanted_triangular\n",
            "2022-04-28 06:11:49,630 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.cut_frac = 0.1\n",
            "2022-04-28 06:11:49,630 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.ratio = 32\n",
            "2022-04-28 06:11:49,630 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.last_epoch = -1\n",
            "2022-04-28 06:11:49,630 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.gradual_unfreezing = False\n",
            "2022-04-28 06:11:49,630 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.discriminative_fine_tuning = False\n",
            "2022-04-28 06:11:49,631 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.decay_factor = 0.38\n",
            "2022-04-28 06:11:49,631 - INFO - allennlp.common.params - trainer.checkpointer.type = default\n",
            "2022-04-28 06:11:49,632 - INFO - allennlp.common.params - trainer.checkpointer.keep_serialized_model_every_num_seconds = None\n",
            "2022-04-28 06:11:49,632 - INFO - allennlp.common.params - trainer.checkpointer.num_serialized_models_to_keep = 1\n",
            "2022-04-28 06:11:49,632 - INFO - allennlp.common.params - trainer.checkpointer.model_save_interval = None\n",
            "2022-04-28 06:11:49,632 - INFO - allennlp.common.params - summary_interval = 100\n",
            "2022-04-28 06:11:49,633 - INFO - allennlp.common.params - histogram_interval = None\n",
            "2022-04-28 06:11:49,633 - INFO - allennlp.common.params - batch_size_interval = None\n",
            "2022-04-28 06:11:49,633 - INFO - allennlp.common.params - should_log_parameter_statistics = True\n",
            "2022-04-28 06:11:49,633 - INFO - allennlp.common.params - should_log_learning_rate = False\n",
            "2022-04-28 06:11:49,633 - INFO - allennlp.common.params - get_batch_num_total = None\n",
            "2022-04-28 06:11:49,638 - WARNING - allennlp.training.trainer - You provided a validation dataset but patience was set to None, meaning that early stopping is disabled\n",
            "2022-04-28 06:11:49,639 - INFO - allennlp.training.trainer - Beginning training.\n",
            "2022-04-28 06:11:49,639 - INFO - allennlp.training.trainer - Epoch 0/9\n",
            "2022-04-28 06:11:49,639 - INFO - allennlp.training.trainer - Worker 0 memory usage: 3.2G\n",
            "2022-04-28 06:11:49,640 - INFO - allennlp.training.trainer - GPU 0 memory usage: 422M\n",
            "2022-04-28 06:11:49,641 - INFO - allennlp.training.trainer - Training\n",
            "2022-04-28 06:11:49,919 - WARNING - allennlp.training.util - Metrics with names beginning with \"_\" will not be logged to the tqdm progress bar.\n",
            "2022-04-28 06:14:16,230 - INFO - allennlp.training.trainer - Validating\n",
            "2022-04-28 06:14:24,878 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-28 06:14:24,880 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.062  |     0.093\n",
            "2022-04-28 06:14:24,882 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.108  |     0.895\n",
            "2022-04-28 06:14:24,883 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.044  |     0.049\n",
            "2022-04-28 06:14:24,885 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.360  |     0.744\n",
            "2022-04-28 06:14:24,886 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.378  |     0.745\n",
            "2022-04-28 06:14:24,886 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.344  |     0.743\n",
            "2022-04-28 06:14:24,887 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.360  |     0.744\n",
            "2022-04-28 06:14:24,890 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.378  |     0.745\n",
            "2022-04-28 06:14:24,891 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.344  |     0.743\n",
            "2022-04-28 06:14:24,892 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.062  |     0.093\n",
            "2022-04-28 06:14:24,893 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.108  |     0.895\n",
            "2022-04-28 06:14:24,895 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.044  |     0.049\n",
            "2022-04-28 06:14:24,896 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |   421.803  |       N/A\n",
            "2022-04-28 06:14:24,897 - INFO - allennlp.training.tensorboard_writer - loss                      |    18.158  |     8.886\n",
            "2022-04-28 06:14:24,897 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  3322.387  |       N/A\n",
            "2022-04-28 06:14:28,222 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs/14lap/seed_0/weights/best.th'.\n",
            "2022-04-28 06:14:29,692 - INFO - allennlp.training.trainer - Epoch duration: 0:02:40.052701\n",
            "2022-04-28 06:14:29,692 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:24:00\n",
            "2022-04-28 06:14:29,692 - INFO - allennlp.training.trainer - Epoch 1/9\n",
            "2022-04-28 06:14:29,693 - INFO - allennlp.training.trainer - Worker 0 memory usage: 3.3G\n",
            "2022-04-28 06:14:29,693 - INFO - allennlp.training.trainer - GPU 0 memory usage: 1.8G\n",
            "2022-04-28 06:14:29,695 - INFO - allennlp.training.trainer - Training\n",
            "2022-04-28 06:16:58,406 - INFO - allennlp.training.trainer - Validating\n",
            "2022-04-28 06:17:06,685 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-28 06:17:06,686 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.385  |     0.477\n",
            "2022-04-28 06:17:06,688 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.501  |     0.709\n",
            "2022-04-28 06:17:06,689 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.313  |     0.359\n",
            "2022-04-28 06:17:06,691 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.753  |     0.791\n",
            "2022-04-28 06:17:06,692 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.785  |     0.804\n",
            "2022-04-28 06:17:06,693 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.724  |     0.778\n",
            "2022-04-28 06:17:06,695 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.753  |     0.791\n",
            "2022-04-28 06:17:06,696 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.785  |     0.804\n",
            "2022-04-28 06:17:06,697 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.724  |     0.778\n",
            "2022-04-28 06:17:06,699 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.385  |     0.477\n",
            "2022-04-28 06:17:06,700 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.501  |     0.709\n",
            "2022-04-28 06:17:06,701 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.313  |     0.359\n",
            "2022-04-28 06:17:06,703 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  1871.789  |       N/A\n",
            "2022-04-28 06:17:06,703 - INFO - allennlp.training.tensorboard_writer - loss                      |     9.737  |     8.807\n",
            "2022-04-28 06:17:06,704 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  3345.945  |       N/A\n",
            "2022-04-28 06:17:09,978 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs/14lap/seed_0/weights/best.th'.\n",
            "2022-04-28 06:17:11,648 - INFO - allennlp.training.trainer - Epoch duration: 0:02:41.955490\n",
            "2022-04-28 06:17:11,648 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:21:28\n",
            "2022-04-28 06:17:11,648 - INFO - allennlp.training.trainer - Epoch 2/9\n",
            "2022-04-28 06:17:11,649 - INFO - allennlp.training.trainer - Worker 0 memory usage: 3.3G\n",
            "2022-04-28 06:17:11,649 - INFO - allennlp.training.trainer - GPU 0 memory usage: 1.8G\n",
            "2022-04-28 06:17:11,652 - INFO - allennlp.training.trainer - Training\n",
            "2022-04-28 06:19:40,299 - INFO - allennlp.training.trainer - Validating\n",
            "2022-04-28 06:19:48,712 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-28 06:19:48,713 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.546  |     0.503\n",
            "2022-04-28 06:19:48,713 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.590  |     0.582\n",
            "2022-04-28 06:19:48,714 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.508  |     0.443\n",
            "2022-04-28 06:19:48,714 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.868  |     0.775\n",
            "2022-04-28 06:19:48,715 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.881  |     0.801\n",
            "2022-04-28 06:19:48,715 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.855  |     0.750\n",
            "2022-04-28 06:19:48,720 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.868  |     0.775\n",
            "2022-04-28 06:19:48,721 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.881  |     0.801\n",
            "2022-04-28 06:19:48,723 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.855  |     0.750\n",
            "2022-04-28 06:19:48,724 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.546  |     0.503\n",
            "2022-04-28 06:19:48,725 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.590  |     0.582\n",
            "2022-04-28 06:19:48,727 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.508  |     0.443\n",
            "2022-04-28 06:19:48,728 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  1871.789  |       N/A\n",
            "2022-04-28 06:19:48,729 - INFO - allennlp.training.tensorboard_writer - loss                      |     7.217  |    13.116\n",
            "2022-04-28 06:19:48,730 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  3345.945  |       N/A\n",
            "2022-04-28 06:19:52,117 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs/14lap/seed_0/weights/best.th'.\n",
            "2022-04-28 06:19:53,752 - INFO - allennlp.training.trainer - Epoch duration: 0:02:42.102842\n",
            "2022-04-28 06:19:53,752 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:18:49\n",
            "2022-04-28 06:19:53,752 - INFO - allennlp.training.trainer - Epoch 3/9\n",
            "2022-04-28 06:19:53,753 - INFO - allennlp.training.trainer - Worker 0 memory usage: 3.3G\n",
            "2022-04-28 06:19:53,754 - INFO - allennlp.training.trainer - GPU 0 memory usage: 1.8G\n",
            "2022-04-28 06:19:53,756 - INFO - allennlp.training.trainer - Training\n",
            "2022-04-28 06:22:19,604 - INFO - allennlp.training.trainer - Validating\n",
            "2022-04-28 06:22:27,917 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-28 06:22:27,918 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.653  |     0.537\n",
            "2022-04-28 06:22:27,919 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.681  |     0.644\n",
            "2022-04-28 06:22:27,920 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.627  |     0.461\n",
            "2022-04-28 06:22:27,922 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.908  |     0.792\n",
            "2022-04-28 06:22:27,923 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.915  |     0.811\n",
            "2022-04-28 06:22:27,925 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.900  |     0.773\n",
            "2022-04-28 06:22:27,926 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.908  |     0.792\n",
            "2022-04-28 06:22:27,927 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.915  |     0.811\n",
            "2022-04-28 06:22:27,929 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.900  |     0.773\n",
            "2022-04-28 06:22:27,930 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.653  |     0.537\n",
            "2022-04-28 06:22:27,931 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.681  |     0.644\n",
            "2022-04-28 06:22:27,933 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.627  |     0.461\n",
            "2022-04-28 06:22:27,934 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  1871.789  |       N/A\n",
            "2022-04-28 06:22:27,935 - INFO - allennlp.training.tensorboard_writer - loss                      |     5.617  |    12.978\n",
            "2022-04-28 06:22:27,936 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  3345.945  |       N/A\n",
            "2022-04-28 06:22:31,159 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs/14lap/seed_0/weights/best.th'.\n",
            "2022-04-28 06:22:33,009 - INFO - allennlp.training.trainer - Epoch duration: 0:02:39.256635\n",
            "2022-04-28 06:22:33,010 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:16:05\n",
            "2022-04-28 06:22:33,011 - INFO - allennlp.training.trainer - Epoch 4/9\n",
            "2022-04-28 06:22:33,011 - INFO - allennlp.training.trainer - Worker 0 memory usage: 3.3G\n",
            "2022-04-28 06:22:33,011 - INFO - allennlp.training.trainer - GPU 0 memory usage: 1.8G\n",
            "2022-04-28 06:22:33,014 - INFO - allennlp.training.trainer - Training\n",
            "2022-04-28 06:24:56,627 - INFO - allennlp.training.trainer - Validating\n",
            "2022-04-28 06:25:04,905 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-28 06:25:04,906 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.725  |     0.582\n",
            "2022-04-28 06:25:04,907 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.758  |     0.593\n",
            "2022-04-28 06:25:04,909 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.695  |     0.571\n",
            "2022-04-28 06:25:04,910 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.946  |     0.789\n",
            "2022-04-28 06:25:04,911 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.954  |     0.764\n",
            "2022-04-28 06:25:04,913 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.937  |     0.815\n",
            "2022-04-28 06:25:04,914 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.946  |     0.789\n",
            "2022-04-28 06:25:04,915 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.954  |     0.764\n",
            "2022-04-28 06:25:04,917 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.937  |     0.815\n",
            "2022-04-28 06:25:04,918 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.725  |     0.582\n",
            "2022-04-28 06:25:04,919 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.758  |     0.593\n",
            "2022-04-28 06:25:04,920 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.695  |     0.571\n",
            "2022-04-28 06:25:04,921 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  1871.789  |       N/A\n",
            "2022-04-28 06:25:04,923 - INFO - allennlp.training.tensorboard_writer - loss                      |     4.259  |    14.813\n",
            "2022-04-28 06:25:04,924 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  3345.945  |       N/A\n",
            "2022-04-28 06:25:08,134 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs/14lap/seed_0/weights/best.th'.\n",
            "2022-04-28 06:25:10,007 - INFO - allennlp.training.trainer - Epoch duration: 0:02:36.996790\n",
            "2022-04-28 06:25:10,008 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:13:20\n",
            "2022-04-28 06:25:10,009 - INFO - allennlp.training.trainer - Epoch 5/9\n",
            "2022-04-28 06:25:10,009 - INFO - allennlp.training.trainer - Worker 0 memory usage: 3.3G\n",
            "2022-04-28 06:25:10,010 - INFO - allennlp.training.trainer - GPU 0 memory usage: 1.8G\n",
            "2022-04-28 06:25:10,012 - INFO - allennlp.training.trainer - Training\n",
            "2022-04-28 06:27:34,478 - INFO - allennlp.training.trainer - Validating\n",
            "2022-04-28 06:27:43,124 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-28 06:27:43,126 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.793  |     0.543\n",
            "2022-04-28 06:27:43,127 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.800  |     0.500\n",
            "2022-04-28 06:27:43,129 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.786  |     0.594\n",
            "2022-04-28 06:27:43,130 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.962  |     0.794\n",
            "2022-04-28 06:27:43,132 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.971  |     0.768\n",
            "2022-04-28 06:27:43,133 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.954  |     0.822\n",
            "2022-04-28 06:27:43,134 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.962  |     0.794\n",
            "2022-04-28 06:27:43,135 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.971  |     0.768\n",
            "2022-04-28 06:27:43,136 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.954  |     0.822\n",
            "2022-04-28 06:27:43,137 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.793  |     0.543\n",
            "2022-04-28 06:27:43,140 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.800  |     0.500\n",
            "2022-04-28 06:27:43,141 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.786  |     0.594\n",
            "2022-04-28 06:27:43,142 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  1871.789  |       N/A\n",
            "2022-04-28 06:27:43,143 - INFO - allennlp.training.tensorboard_writer - loss                      |     3.408  |    22.138\n",
            "2022-04-28 06:27:43,144 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  3345.945  |       N/A\n",
            "2022-04-28 06:27:46,811 - INFO - allennlp.training.trainer - Epoch duration: 0:02:36.802464\n",
            "2022-04-28 06:27:46,812 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:10:38\n",
            "2022-04-28 06:27:46,812 - INFO - allennlp.training.trainer - Epoch 6/9\n",
            "2022-04-28 06:27:46,812 - INFO - allennlp.training.trainer - Worker 0 memory usage: 3.3G\n",
            "2022-04-28 06:27:46,813 - INFO - allennlp.training.trainer - GPU 0 memory usage: 1.8G\n",
            "2022-04-28 06:27:46,815 - INFO - allennlp.training.trainer - Training\n",
            "2022-04-28 06:30:10,344 - INFO - allennlp.training.trainer - Validating\n",
            "2022-04-28 06:30:18,637 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-28 06:30:18,638 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.839  |     0.595\n",
            "2022-04-28 06:30:18,639 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.853  |     0.584\n",
            "2022-04-28 06:30:18,639 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.825  |     0.606\n",
            "2022-04-28 06:30:18,640 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.968  |     0.808\n",
            "2022-04-28 06:30:18,640 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.972  |     0.778\n",
            "2022-04-28 06:30:18,641 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.963  |     0.840\n",
            "2022-04-28 06:30:18,641 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.968  |     0.808\n",
            "2022-04-28 06:30:18,645 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.972  |     0.778\n",
            "2022-04-28 06:30:18,648 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.963  |     0.840\n",
            "2022-04-28 06:30:18,649 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.839  |     0.595\n",
            "2022-04-28 06:30:18,651 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.853  |     0.584\n",
            "2022-04-28 06:30:18,652 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.825  |     0.606\n",
            "2022-04-28 06:30:18,653 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  1871.789  |       N/A\n",
            "2022-04-28 06:30:18,654 - INFO - allennlp.training.tensorboard_writer - loss                      |     2.649  |    19.263\n",
            "2022-04-28 06:30:18,655 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  3345.945  |       N/A\n",
            "2022-04-28 06:30:22,103 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs/14lap/seed_0/weights/best.th'.\n",
            "2022-04-28 06:30:23,804 - INFO - allennlp.training.trainer - Epoch duration: 0:02:36.992595\n",
            "2022-04-28 06:30:23,805 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:07:57\n",
            "2022-04-28 06:30:23,805 - INFO - allennlp.training.trainer - Epoch 7/9\n",
            "2022-04-28 06:30:23,805 - INFO - allennlp.training.trainer - Worker 0 memory usage: 3.3G\n",
            "2022-04-28 06:30:23,807 - INFO - allennlp.training.trainer - GPU 0 memory usage: 1.8G\n",
            "2022-04-28 06:30:23,809 - INFO - allennlp.training.trainer - Training\n",
            "2022-04-28 06:32:46,855 - INFO - allennlp.training.trainer - Validating\n",
            "2022-04-28 06:32:55,029 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-28 06:32:55,030 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.879  |     0.588\n",
            "2022-04-28 06:32:55,032 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.881  |     0.597\n",
            "2022-04-28 06:32:55,033 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.876  |     0.580\n",
            "2022-04-28 06:32:55,034 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.979  |     0.793\n",
            "2022-04-28 06:32:55,036 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.980  |     0.767\n",
            "2022-04-28 06:32:55,037 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.979  |     0.822\n",
            "2022-04-28 06:32:55,038 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.979  |     0.793\n",
            "2022-04-28 06:32:55,039 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.980  |     0.767\n",
            "2022-04-28 06:32:55,041 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.979  |     0.822\n",
            "2022-04-28 06:32:55,042 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.879  |     0.588\n",
            "2022-04-28 06:32:55,043 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.881  |     0.597\n",
            "2022-04-28 06:32:55,044 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.876  |     0.580\n",
            "2022-04-28 06:32:55,046 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  1871.789  |       N/A\n",
            "2022-04-28 06:32:55,046 - INFO - allennlp.training.tensorboard_writer - loss                      |     1.961  |    22.860\n",
            "2022-04-28 06:32:55,048 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  3345.945  |       N/A\n",
            "2022-04-28 06:32:58,610 - INFO - allennlp.training.trainer - Epoch duration: 0:02:34.804695\n",
            "2022-04-28 06:32:58,610 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:05:17\n",
            "2022-04-28 06:32:58,610 - INFO - allennlp.training.trainer - Epoch 8/9\n",
            "2022-04-28 06:32:58,610 - INFO - allennlp.training.trainer - Worker 0 memory usage: 3.3G\n",
            "2022-04-28 06:32:58,612 - INFO - allennlp.training.trainer - GPU 0 memory usage: 1.8G\n",
            "2022-04-28 06:32:58,614 - INFO - allennlp.training.trainer - Training\n",
            "2022-04-28 06:35:20,954 - INFO - allennlp.training.trainer - Validating\n",
            "2022-04-28 06:35:29,203 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-28 06:35:29,204 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.925  |     0.590\n",
            "2022-04-28 06:35:29,205 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.931  |     0.556\n",
            "2022-04-28 06:35:29,206 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.918  |     0.629\n",
            "2022-04-28 06:35:29,207 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.988  |     0.807\n",
            "2022-04-28 06:35:29,209 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.990  |     0.769\n",
            "2022-04-28 06:35:29,210 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.987  |     0.848\n",
            "2022-04-28 06:35:29,211 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.988  |     0.807\n",
            "2022-04-28 06:35:29,212 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.990  |     0.769\n",
            "2022-04-28 06:35:29,214 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.987  |     0.848\n",
            "2022-04-28 06:35:29,215 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.925  |     0.590\n",
            "2022-04-28 06:35:29,216 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.931  |     0.556\n",
            "2022-04-28 06:35:29,218 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.918  |     0.629\n",
            "2022-04-28 06:35:29,219 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  1871.789  |       N/A\n",
            "2022-04-28 06:35:29,220 - INFO - allennlp.training.tensorboard_writer - loss                      |     1.314  |    30.042\n",
            "2022-04-28 06:35:29,221 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  3345.945  |       N/A\n",
            "2022-04-28 06:35:32,689 - INFO - allennlp.training.trainer - Epoch duration: 0:02:34.078647\n",
            "2022-04-28 06:35:32,689 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:02:38\n",
            "2022-04-28 06:35:32,689 - INFO - allennlp.training.trainer - Epoch 9/9\n",
            "2022-04-28 06:35:32,690 - INFO - allennlp.training.trainer - Worker 0 memory usage: 3.3G\n",
            "2022-04-28 06:35:32,690 - INFO - allennlp.training.trainer - GPU 0 memory usage: 1.8G\n",
            "2022-04-28 06:35:32,692 - INFO - allennlp.training.trainer - Training\n",
            "2022-04-28 06:37:54,357 - INFO - allennlp.training.trainer - Validating\n",
            "2022-04-28 06:38:02,626 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-04-28 06:38:02,626 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.937  |     0.613\n",
            "2022-04-28 06:38:02,627 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.936  |     0.609\n",
            "2022-04-28 06:38:02,627 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.939  |     0.617\n",
            "2022-04-28 06:38:02,628 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.993  |     0.809\n",
            "2022-04-28 06:38:02,628 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.994  |     0.772\n",
            "2022-04-28 06:38:02,631 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.991  |     0.850\n",
            "2022-04-28 06:38:02,633 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.993  |     0.809\n",
            "2022-04-28 06:38:02,635 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.994  |     0.772\n",
            "2022-04-28 06:38:02,637 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.991  |     0.850\n",
            "2022-04-28 06:38:02,638 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.937  |     0.613\n",
            "2022-04-28 06:38:02,639 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.936  |     0.609\n",
            "2022-04-28 06:38:02,641 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.939  |     0.617\n",
            "2022-04-28 06:38:02,642 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  1871.789  |       N/A\n",
            "2022-04-28 06:38:02,643 - INFO - allennlp.training.tensorboard_writer - loss                      |     0.991  |    28.955\n",
            "2022-04-28 06:38:02,644 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  3345.945  |       N/A\n",
            "2022-04-28 06:38:06,244 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs/14lap/seed_0/weights/best.th'.\n",
            "2022-04-28 06:38:08,293 - INFO - allennlp.training.trainer - Epoch duration: 0:02:35.603490\n",
            "2022-04-28 06:38:08,293 - INFO - allennlp.training.checkpointer - loading best weights\n",
            "2022-04-28 06:38:08,700 - INFO - allennlp.commands.train - To evaluate on the test set after training, pass the 'evaluate_on_test' flag, or use the 'allennlp evaluate' command.\n",
            "2022-04-28 06:38:08,700 - INFO - allennlp.common.util - Metrics: {\n",
            "\"best_epoch\": 9,\n",
            "\"peak_worker_0_memory_MB\": 3345.9453125,\n",
            "\"peak_gpu_0_memory_MB\": 1871.78857421875,\n",
            "\"training_duration\": \"0:26:13.005685\",\n",
            "\"training_start_epoch\": 0,\n",
            "\"training_epochs\": 9,\n",
            "\"epoch\": 9,\n",
            "\"training__None__ner_precision\": 0.9940944881889764,\n",
            "\"training__None__ner_recall\": 0.9909733124018838,\n",
            "\"training__None__ner_f1\": 0.9925314465408805,\n",
            "\"training__MEAN__ner_precision\": 0.9940944881889764,\n",
            "\"training__MEAN__ner_recall\": 0.9909733124018838,\n",
            "\"training__MEAN__ner_f1\": 0.9925314465408805,\n",
            "\"training__None__relation_precision\": 0.9358361774744027,\n",
            "\"training__None__relation_recall\": 0.939041095890411,\n",
            "\"training__None__relation_f1\": 0.9374358974358975,\n",
            "\"training_MEAN__relation_precision\": 0.9358361774744027,\n",
            "\"training_MEAN__relation_recall\": 0.939041095890411,\n",
            "\"training_MEAN__relation_f1\": 0.9374358974358975,\n",
            "\"training_loss\": 0.9912893726794216,\n",
            "\"training_worker_0_memory_MB\": 3345.9453125,\n",
            "\"training_gpu_0_memory_MB\": 1871.78857421875,\n",
            "\"validation__None__ner_precision\": 0.7715582450832073,\n",
            "\"validation__None__ner_recall\": 0.85,\n",
            "\"validation__None__ner_f1\": 0.8088818398096748,\n",
            "\"validation__MEAN__ner_precision\": 0.7715582450832073,\n",
            "\"validation__MEAN__ner_recall\": 0.85,\n",
            "\"validation__MEAN__ner_f1\": 0.8088818398096748,\n",
            "\"validation__None__relation_precision\": 0.6085714285714285,\n",
            "\"validation__None__relation_recall\": 0.6173913043478261,\n",
            "\"validation__None__relation_f1\": 0.6129496402877698,\n",
            "\"validation_MEAN__relation_precision\": 0.6085714285714285,\n",
            "\"validation_MEAN__relation_recall\": 0.6173913043478261,\n",
            "\"validation_MEAN__relation_f1\": 0.6129496402877698,\n",
            "\"validation_loss\": 28.954841242617867,\n",
            "\"best_validation__None__ner_precision\": 0.7715582450832073,\n",
            "\"best_validation__None__ner_recall\": 0.85,\n",
            "\"best_validation__None__ner_f1\": 0.8088818398096748,\n",
            "\"best_validation__MEAN__ner_precision\": 0.7715582450832073,\n",
            "\"best_validation__MEAN__ner_recall\": 0.85,\n",
            "\"best_validation__MEAN__ner_f1\": 0.8088818398096748,\n",
            "\"best_validation__None__relation_precision\": 0.6085714285714285,\n",
            "\"best_validation__None__relation_recall\": 0.6173913043478261,\n",
            "\"best_validation__None__relation_f1\": 0.6129496402877698,\n",
            "\"best_validation_MEAN__relation_precision\": 0.6085714285714285,\n",
            "\"best_validation_MEAN__relation_recall\": 0.6173913043478261,\n",
            "\"best_validation_MEAN__relation_f1\": 0.6129496402877698,\n",
            "\"best_validation_loss\": 28.954841242617867\n",
            "}\n",
            "2022-04-28 06:38:08,708 - INFO - allennlp.models.archival - archiving weights and vocabulary to outputs/14lap/seed_0/weights/model.tar.gz\n"
          ]
        }
      ],
      "source": [
        "# Train SpanModel from scratch\n",
        "random_seed = 0\n",
        "path_train = f\"aste/data/triplet_data/{data_name}/train.txt\"\n",
        "path_dev = f\"aste/data/triplet_data/{data_name}/dev.txt\"\n",
        "path_test = f\"aste/data/triplet_data/{data_name}/test.txt\"\n",
        "save_dir = f\"outputs/{data_name}/seed_{random_seed}\"\n",
        "\n",
        "model = SpanModel(save_dir=save_dir, random_seed=random_seed)\n",
        "model.fit(path_train, path_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjyiKWjSF7oZ",
        "outputId": "1b12d91b-3d13-41a4-fb41-105b970cab01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'command': 'cd /content && allennlp predict outputs/14lap/seed_0/weights/model.tar.gz /content/outputs/14lap/seed_0/temp_data/pred_in.json --predictor span_model --include-package span_model --use-dataset-reader  --output-file outputs/14lap/seed_0/temp_data/pred_out.json --cuda-device 0 --silent '}\n",
            "################################################################################\n",
            "################################################################################\n",
            "{'locals': ('use_ner_embeds', False)}\n",
            "{'locals': ('span_extractor_type', 'endpoint')}\n",
            "{'locals': ('use_double_mix_embedder', False)}\n",
            "{'locals': ('relation_head_type', 'proper')}\n",
            "{'locals': ('use_span_width_embeds', True)}\n",
            "{'ner_loss_fn': CrossEntropyLoss()}\n",
            "{'unused_keys': dict_keys(['focal_loss_gamma', 'use_bi_affine_pruner', 'use_classify_mask_pruner', 'use_focal_loss', 'use_ner_scores_for_prune', 'use_ope_down_project', 'use_pair_feature_multiply', 'use_pairwise_down_project', 'use_span_loss_for_pruners', 'use_span_pair_aux_task', 'use_span_pair_aux_task_after_prune'])}\n",
            "{'locals': {'self': ProperRelationExtractor(), 'make_feedforward': <function SpanModel.__init__.<locals>.make_feedforward at 0x7f3a406de9e0>, 'span_emb_dim': 1556, 'feature_size': 20, 'spans_per_word': 0.5, 'positive_label_weight': 1.0, 'regularizer': None, 'use_distance_embeds': True, 'use_pair_feature_maxpool': False, 'use_pair_feature_cls': False, 'use_bi_affine_classifier': False, 'neg_class_weight': -1, 'span_length_loss_weight_gamma': 0, 'use_bag_pair_scorer': False, 'use_bi_affine_v2': False, 'use_pruning': True, 'use_single_pool': False, 'kwargs': {'focal_loss_gamma': 2, 'use_bi_affine_pruner': False, 'use_classify_mask_pruner': False, 'use_focal_loss': False, 'use_ner_scores_for_prune': False, 'use_ope_down_project': False, 'use_pair_feature_multiply': False, 'use_pairwise_down_project': False, 'use_span_loss_for_pruners': False, 'use_span_pair_aux_task': False, 'use_span_pair_aux_task_after_prune': False}, 'vocab': Vocabulary with namespaces:  None__tag_labels, Size: 9 || None__ner_labels, Size: 3 || None__relation_labels, Size: 3 || Non Padded Namespaces: {'*labels', '*tags'}, '__class__': <class 'span_model.models.relation_proper.ProperRelationExtractor'>}}\n",
            "{'token_emb_dim': 768, 'span_emb_dim': 1556, 'relation_scorer_dim': 3240}\n",
            "{'relation_loss_fn': CrossEntropyLoss()}\n",
            "{'file_path': '/content/outputs/14lap/seed_0/temp_data/pred_in.json', 'stats': Stats(entity_total=328, entity_drop=0, relation_total=328, relation_drop=0, graph_total=0, graph_edges=0, grid_total=110829, grid_paired=328)}\n",
            "{\n",
            "  \"path_pred\": \"pred.txt\",\n",
            "  \"path_gold\": \"aste/data/triplet_data/14lap/test.txt\",\n",
            "  \"precision\": 0.6197183098591549,\n",
            "  \"recall\": 0.567219152854512,\n",
            "  \"score\": 0.5923076923076923\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Evaluate SpanModel F1 Score\n",
        "import json\n",
        "\n",
        "path_pred = \"pred.txt\"\n",
        "model.predict(path_in=path_test, path_out=path_pred)\n",
        "results = model.score(path_pred, path_test)\n",
        "print(json.dumps(results, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Rr7NfLTYTIeO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Span ASTE Demo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}